{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "328062bf",
   "metadata": {},
   "source": [
    "# Clickbait detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3941fb40",
   "metadata": {},
   "source": [
    "## Normalización del dataset combinando los aspectos mencionados en las especificaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d2ccedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añadir el directorio 'src' al sys.path\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9009aaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener la ruta absoluta de la carpeta 'src' para que sea accesible desde el notebook\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10a8a6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar la función de normalización\n",
    "from preprocessing import normalize_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c8f8dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar pandas para cargar y manipular el dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd945c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset\n",
    "df = pd.read_csv(\"../data/TA1C_dataset_detection_train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94c3dc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Tweet Date', 'Media Name', 'Media Origin'], axis=1)\n",
    "# Aplicar cada tipo de normalización\n",
    "df['tokenized_text'] = df['Teaser Text'].apply(lambda x: normalize_text(x, mode=\"tokenization\"))\n",
    "df['cleaned_text'] = df['Teaser Text'].apply(lambda x: normalize_text(x, mode=\"text_cleaning\"))\n",
    "df['no_stopwords_text'] = df['Teaser Text'].apply(lambda x: normalize_text(x, mode=\"remove_stopwords\"))\n",
    "df['lemmatized_text'] = df['Teaser Text'].apply(lambda x: normalize_text(x, mode=\"lemmatization\"))\n",
    "df['tokenized_cleaned_text'] = df['Teaser Text'].apply(lambda x: normalize_text(x, mode=\"text_cleaning\")).apply(lambda x: normalize_text(x, mode=\"tokenization\"))\n",
    "df[\"tokenized_cleaned_text_no_stopwords\"] = df['Teaser Text'].apply(lambda x: normalize_text(x, mode=\"text_cleaning\")).apply(lambda x: normalize_text(x, mode=\"remove_stopwords\"))\n",
    "df[\"tokenized_cleaned_text_no_stopwords_lemmatized\"] = df['tokenized_cleaned_text_no_stopwords'].apply(lambda x: normalize_text(\" \".join(x), mode='lemmatization'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5090b313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ejemplos de normalización:\n",
      "                                         Teaser Text  \\\n",
      "0  #SegundaDivisión  | La fortaleza del ataque: R...   \n",
      "1  Jorge Lanata a los argentinos que se van a Uru...   \n",
      "2  Raffo: “Los montevideanos deben estar alerta p...   \n",
      "3  Ecos del universo: joven uruguayo desentraña (...   \n",
      "4  Propuesta quinquenal de ANEP: aumento de 3,8% ...   \n",
      "\n",
      "                                      tokenized_text  \\\n",
      "0  [#, SegundaDivisión,  , |, La, fortaleza, del,...   \n",
      "1  [Jorge, Lanata, a, los, argentinos, que, se, v...   \n",
      "2  [Raffo, :, “, Los, montevideanos, deben, estar...   \n",
      "3  [Ecos, del, universo, :, joven, uruguayo, dese...   \n",
      "4  [Propuesta, quinquenal, de, ANEP, :, aumento, ...   \n",
      "\n",
      "                                        cleaned_text  \\\n",
      "0  segundadivisión   la fortaleza del ataque ramp...   \n",
      "1  jorge lanata a los argentinos que se van a uru...   \n",
      "2  raffo “los montevideanos deben estar alerta po...   \n",
      "3  ecos del universo joven uruguayo desentraña y ...   \n",
      "4  propuesta quinquenal de anep aumento de  del p...   \n",
      "\n",
      "                                   no_stopwords_text  \\\n",
      "0  [#, SegundaDivisión,  , |, fortaleza, ataque, ...   \n",
      "1  [Jorge, Lanata, argentinos, Uruguay, :, \", Irs...   \n",
      "2  [Raffo, :, “, montevideanos, alerta, errores, ...   \n",
      "3  [Ecos, universo, :, joven, uruguayo, desentrañ...   \n",
      "4  [Propuesta, quinquenal, ANEP, :, aumento, 3,8%...   \n",
      "\n",
      "                                     lemmatized_text  \\\n",
      "0  [#, segundadivisión,  , |, el, fortaleza, del,...   \n",
      "1  [Jorge, Lanata, a, el, argentino, que, él, ir,...   \n",
      "2  [Raffo, :, “, el, montevideano, deber, estar, ...   \n",
      "3  [eco, del, universo, :, joven, uruguayo, desen...   \n",
      "4  [propuesta, quinquenal, de, ANEP, :, aumento, ...   \n",
      "\n",
      "                              tokenized_cleaned_text  \\\n",
      "0  [segundadivisión,   , la, fortaleza, del, ataq...   \n",
      "1  [jorge, lanata, a, los, argentinos, que, se, v...   \n",
      "2  [raffo, “, los, montevideanos, deben, estar, a...   \n",
      "3  [ecos, del, universo, joven, uruguayo, desentr...   \n",
      "4  [propuesta, quinquenal, de, anep, aumento, de,...   \n",
      "\n",
      "                 tokenized_cleaned_text_no_stopwords  \\\n",
      "0  [segundadivisión,   , fortaleza, ataque, rampl...   \n",
      "1  [jorge, lanata, argentinos, uruguay, irse, fra...   \n",
      "2  [raffo, “, montevideanos, alerta, errores, gru...   \n",
      "3  [ecos, universo, joven, uruguayo, desentraña, ...   \n",
      "4  [propuesta, quinquenal, anep, aumento,  , pres...   \n",
      "\n",
      "      tokenized_cleaned_text_no_stopwords_lemmatized  \n",
      "0  [segundadivisión,    , fortaleza, ataque, ramp...  \n",
      "1  [jorge, lanata, argentinos, uruguay, ir él, fr...  \n",
      "2  [raffo, “, montevidea yo, alertar, error, grue...  \n",
      "3  [eco, universo, joven, uruguayo, desentraña, e...  \n",
      "4  [propuesta, quinquenal, anep, aumento,   , pre...  \n"
     ]
    }
   ],
   "source": [
    "# Mostrar ejemplos de cada tipo de normalización\n",
    "print(\"\\nEjemplos de normalización:\")\n",
    "print(df[['Teaser Text', 'tokenized_text', 'cleaned_text', 'no_stopwords_text', 'lemmatized_text', 'tokenized_cleaned_text', 'tokenized_cleaned_text_no_stopwords', 'tokenized_cleaned_text_no_stopwords_lemmatized']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "485b8b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset con normalizaciones guardado en '../data/TA1C_dataset_detection_train_cleaned.csv'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Guardar el dataset con todas las columnas de normalización\n",
    "output_path = \"../data/TA1C_dataset_detection_train_cleaned.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"Dataset con normalizaciones guardado en '{output_path}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0f8828",
   "metadata": {},
   "source": [
    "### Dividimos el dataset dentro del Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88902a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjuntos de entrenamiento y desarrollo guardados en '../data/'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividir el dataset en conjuntos de entrenamiento y desarrollo\n",
    "train_df, dev_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.25,  # 25% para desarrollo\n",
    "    random_state=0,  # Para reproducibilidad\n",
    "    stratify=df['Tag Value'],  # Estratificar según la columna de clase\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Guardar los conjuntos en archivos CSV\n",
    "train_df.to_csv(\"../data/TA1C_dataset_detection_train_split.csv\", index=False)\n",
    "dev_df.to_csv(\"../data/TA1C_dataset_detection_dev_split.csv\", index=False)\n",
    "\n",
    "print(\"Conjuntos de entrenamiento y desarrollo guardados en '../data/'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf7d4c9",
   "metadata": {},
   "source": [
    "### Representación de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d94fdc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Tweet ID', 'Teaser Text', 'Tag Value', 'tokenized_text',\n",
      "       'cleaned_text', 'no_stopwords_text', 'lemmatized_text',\n",
      "       'tokenized_cleaned_text', 'tokenized_cleaned_text_no_stopwords',\n",
      "       'tokenized_cleaned_text_no_stopwords_lemmatized'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Cargar los conjuntos de entrenamiento y desarrollo\n",
    "train_df = pd.read_csv(\"../data/TA1C_dataset_detection_train_split.csv\")\n",
    "dev_df = pd.read_csv(\"../data/TA1C_dataset_detection_dev_split.csv\")\n",
    "\n",
    "# Verificar las columnas disponibles\n",
    "print(train_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e66bfb",
   "metadata": {},
   "source": [
    "## Usando tokenización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79d461c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuración: ngram_range=(1, 1), representación=tfidf\n",
      "Dimensiones de X_train: (2100, 11434)\n",
      "Dimensiones de X_dev: (700, 11434)\n",
      "Configuración: ngram_range=(1, 2), representación=tfidf\n",
      "Dimensiones de X_train: (2100, 44247)\n",
      "Dimensiones de X_dev: (700, 44247)\n",
      "Configuración: ngram_range=(1, 3), representación=tfidf\n",
      "Dimensiones de X_train: (2100, 85357)\n",
      "Dimensiones de X_dev: (700, 85357)\n",
      "Configuración: ngram_range=(1, 2), representación=binary\n",
      "Dimensiones de X_train: (2100, 44247)\n",
      "Dimensiones de X_dev: (700, 44247)\n",
      "Configuración: ngram_range=(1, 2), representación=frequency\n",
      "Dimensiones de X_train: (2100, 44247)\n",
      "Dimensiones de X_dev: (700, 44247)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Probar diferentes configuraciones de n-gramas y representaciones\n",
    "configurations = [\n",
    "    {\"ngram_range\": (1, 1), \"representation\": \"tfidf\"},  # Unigramas con TF-IDF\n",
    "    {\"ngram_range\": (1, 2), \"representation\": \"tfidf\"},  # Unigramas + Bigramas con TF-IDF\n",
    "    {\"ngram_range\": (1, 3), \"representation\": \"tfidf\"},  # Unigramas + Bigramas + Trigramas con TF-IDF\n",
    "    {\"ngram_range\": (1, 2), \"representation\": \"binary\"},  # Unigramas + Bigramas con representación binaria\n",
    "    {\"ngram_range\": (1, 2), \"representation\": \"frequency\"},  # Unigramas + Bigramas con frecuencia\n",
    "]\n",
    "\n",
    "for config in configurations:\n",
    "    print(f\"Configuración: ngram_range={config['ngram_range']}, representación={config['representation']}\")\n",
    "    \n",
    "    # Configurar el vectorizador\n",
    "    if config[\"representation\"] == \"tfidf\":\n",
    "        vectorizer = TfidfVectorizer(ngram_range=config[\"ngram_range\"])\n",
    "    elif config[\"representation\"] == \"binary\":\n",
    "        vectorizer = TfidfVectorizer(ngram_range=config[\"ngram_range\"], binary=True)\n",
    "    elif config[\"representation\"] == \"frequency\":\n",
    "        vectorizer = TfidfVectorizer(ngram_range=config[\"ngram_range\"], use_idf=False)\n",
    "    \n",
    "    # Crear representaciones para el conjunto de entrenamiento y desarrollo\n",
    "    X_train = vectorizer.fit_transform(train_df['tokenized_text'])\n",
    "    X_dev = vectorizer.transform(dev_df['tokenized_text'])\n",
    "    \n",
    "    # Verificar las dimensiones\n",
    "    print(f\"Dimensiones de X_train: {X_train.shape}\")\n",
    "    print(f\"Dimensiones de X_dev: {X_dev.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cde7336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones reducidas de X_train: (2100, 100)\n",
      "Dimensiones reducidas de X_dev: (700, 100)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Reducir dimensionalidad con TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=100, random_state=0)  # Reducir a 100 dimensiones\n",
    "X_train_reduced = svd.fit_transform(X_train)\n",
    "X_dev_reduced = svd.transform(X_dev)\n",
    "\n",
    "# Verificar las dimensiones después de la reducción\n",
    "print(f\"Dimensiones reducidas de X_train: {X_train_reduced.shape}\")\n",
    "print(f\"Dimensiones reducidas de X_dev: {X_dev_reduced.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70b23b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir etiquetas de texto a valores numéricos\n",
    "label_mapping = {'Clickbait': 1, 'No': 0}\n",
    "train_df['Tag Value'] = train_df['Tag Value'].map(label_mapping)\n",
    "dev_df['Tag Value'] = dev_df['Tag Value'].map(label_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231899c6",
   "metadata": {},
   "source": [
    "### Logistic Regression y Validación Cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc12a002",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input y contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Evaluar el modelo con validación cruzada usando f1_macro\u001b[39;00m\n\u001b[32m     12\u001b[39m f1_macro_scorer = make_scorer(f1_score, average=\u001b[33m'\u001b[39m\u001b[33mmacro\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m scores = \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_reduced\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTag Value\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43mf1_macro_scorer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Imprimir los resultados\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mF1-macro scores por fold: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscores\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:684\u001b[39m, in \u001b[36mcross_val_score\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[39m\n\u001b[32m    681\u001b[39m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[32m    682\u001b[39m scorer = check_scoring(estimator, scoring=scoring)\n\u001b[32m--> \u001b[39m\u001b[32m684\u001b[39m cv_results = \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mscore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[33m\"\u001b[39m\u001b[33mtest_score\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:403\u001b[39m, in \u001b[36mcross_validate\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[39m\n\u001b[32m    400\u001b[39m     routed_params.estimator = Bunch(fit=params)\n\u001b[32m    401\u001b[39m     routed_params.scorer = Bunch(score={})\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m indices = \u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_indices:\n\u001b[32m    405\u001b[39m     \u001b[38;5;66;03m# materialize the indices since we need to store them in the returned dict\u001b[39;00m\n\u001b[32m    406\u001b[39m     indices = \u001b[38;5;28mlist\u001b[39m(indices)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:881\u001b[39m, in \u001b[36mStratifiedKFold.split\u001b[39m\u001b[34m(self, X, y, groups)\u001b[39m\n\u001b[32m    876\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m groups \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    877\u001b[39m     warnings.warn(\n\u001b[32m    878\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe groups parameter is ignored by \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[32m    880\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m881\u001b[39m y = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43my\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().split(X, y, groups)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/utils/validation.py:1107\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1102\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m expected <= 2.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1103\u001b[39m         % (array.ndim, estimator_name)\n\u001b[32m   1104\u001b[39m     )\n\u001b[32m   1106\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[32m-> \u001b[39m\u001b[32m1107\u001b[39m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1111\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1112\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[32m   1115\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[32m   1116\u001b[39m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/utils/validation.py:120\u001b[39m, in \u001b[36m_assert_all_finite\u001b[39m\u001b[34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/utils/validation.py:169\u001b[39m, in \u001b[36m_assert_all_finite_element_wise\u001b[39m\u001b[34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name == \u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[32m    153\u001b[39m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[32m    155\u001b[39m     msg_err += (\n\u001b[32m    156\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not accept missing values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    167\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m#estimators-that-handle-nan-values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    168\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[31mValueError\u001b[39m: Input y contains NaN."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "# Configurar validación cruzada estratificada\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# Definir el modelo\n",
    "model = LogisticRegression(max_iter=200)\n",
    "\n",
    "# Evaluar el modelo con validación cruzada usando f1_macro\n",
    "f1_macro_scorer = make_scorer(f1_score, average='macro')\n",
    "scores = cross_val_score(model, X_train_reduced, train_df['Tag Value'], cv=cv, scoring=f1_macro_scorer)\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(f\"F1-macro scores por fold: {scores}\")\n",
    "print(f\"F1-macro promedio: {scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1aa044",
   "metadata": {},
   "source": [
    "## Usando lematización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dae418a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuración: ngram_range=(1, 1), representación=tfidf\n",
      "Dimensiones de X_train: (2100, 9183)\n",
      "Dimensiones de X_dev: (700, 9183)\n",
      "Configuración: ngram_range=(1, 2), representación=tfidf\n",
      "Dimensiones de X_train: (2100, 39506)\n",
      "Dimensiones de X_dev: (700, 39506)\n",
      "Configuración: ngram_range=(1, 3), representación=tfidf\n",
      "Dimensiones de X_train: (2100, 79900)\n",
      "Dimensiones de X_dev: (700, 79900)\n",
      "Configuración: ngram_range=(1, 2), representación=binary\n",
      "Dimensiones de X_train: (2100, 39506)\n",
      "Dimensiones de X_dev: (700, 39506)\n",
      "Configuración: ngram_range=(1, 2), representación=frequency\n",
      "Dimensiones de X_train: (2100, 39506)\n",
      "Dimensiones de X_dev: (700, 39506)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Probar diferentes configuraciones de n-gramas y representaciones\n",
    "configurations = [\n",
    "    {\"ngram_range\": (1, 1), \"representation\": \"tfidf\"},  # Unigramas con TF-IDF\n",
    "    {\"ngram_range\": (1, 2), \"representation\": \"tfidf\"},  # Unigramas + Bigramas con TF-IDF\n",
    "    {\"ngram_range\": (1, 3), \"representation\": \"tfidf\"},  # Unigramas + Bigramas + Trigramas con TF-IDF\n",
    "    {\"ngram_range\": (1, 2), \"representation\": \"binary\"},  # Unigramas + Bigramas con representación binaria\n",
    "    {\"ngram_range\": (1, 2), \"representation\": \"frequency\"},  # Unigramas + Bigramas con frecuencia\n",
    "]\n",
    "\n",
    "for config in configurations:\n",
    "    print(f\"Configuración: ngram_range={config['ngram_range']}, representación={config['representation']}\")\n",
    "    \n",
    "    # Configurar el vectorizador\n",
    "    if config[\"representation\"] == \"tfidf\":\n",
    "        vectorizer = TfidfVectorizer(ngram_range=config[\"ngram_range\"])\n",
    "    elif config[\"representation\"] == \"binary\":\n",
    "        vectorizer = TfidfVectorizer(ngram_range=config[\"ngram_range\"], binary=True)\n",
    "    elif config[\"representation\"] == \"frequency\":\n",
    "        vectorizer = TfidfVectorizer(ngram_range=config[\"ngram_range\"], use_idf=False)\n",
    "    \n",
    "    # Crear representaciones para el conjunto de entrenamiento y desarrollo\n",
    "    X_train = vectorizer.fit_transform(train_df['lemmatized_text'])\n",
    "    X_dev = vectorizer.transform(dev_df['lemmatized_text'])\n",
    "    \n",
    "    # Verificar las dimensiones\n",
    "    print(f\"Dimensiones de X_train: {X_train.shape}\")\n",
    "    print(f\"Dimensiones de X_dev: {X_dev.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fa5a956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones reducidas de X_train: (2100, 100)\n",
      "Dimensiones reducidas de X_dev: (700, 100)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Reducir dimensionalidad con TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=100, random_state=0)  # Reducir a 100 dimensiones\n",
    "X_train_reduced = svd.fit_transform(X_train)\n",
    "X_dev_reduced = svd.transform(X_dev)\n",
    "\n",
    "# Verificar las dimensiones después de la reducción\n",
    "print(f\"Dimensiones reducidas de X_train: {X_train_reduced.shape}\")\n",
    "print(f\"Dimensiones reducidas de X_dev: {X_dev_reduced.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22f25a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir etiquetas de texto a valores numéricos\n",
    "label_mapping = {'Clickbait': 1, 'No': 0}\n",
    "train_df['Tag Value'] = train_df['Tag Value'].map(label_mapping)\n",
    "dev_df['Tag Value'] = dev_df['Tag Value'].map(label_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9378fa2e",
   "metadata": {},
   "source": [
    "### Logistic Regression y Validación Cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d13f932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-macro scores por fold: [0.57350414 0.57255747 0.61648997 0.60008246 0.55428571]\n",
      "F1-macro promedio: 0.5834\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "# Configurar validación cruzada estratificada\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# Definir el modelo\n",
    "model = LogisticRegression(max_iter=200)\n",
    "\n",
    "# Evaluar el modelo con validación cruzada usando f1_macro\n",
    "f1_macro_scorer = make_scorer(f1_score, average='macro')\n",
    "scores = cross_val_score(model, X_train_reduced, train_df['Tag Value'], cv=cv, scoring=f1_macro_scorer)\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(f\"F1-macro scores por fold: {scores}\")\n",
    "print(f\"F1-macro promedio: {scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2717a2d",
   "metadata": {},
   "source": [
    "### Entrenamiento del modelo utilizando algoritmos de ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6679ac81",
   "metadata": {},
   "source": [
    "#### Naive Bayes Multinominal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f64e762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naïve Bayes Multinomial (sin TruncatedSVD):\n",
      "F1-macro scores por fold: [0.41666667 0.41666667 0.42551064 0.41747573 0.42638889]\n",
      "F1-macro promedio: 0.4205\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Definir el modelo de Naïve Bayes Multinomial\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "# Evaluar el modelo con validación cruzada usando las representaciones originales (X_train)\n",
    "nb_scores = cross_val_score(nb_model, X_train, train_df['Tag Value'], cv=5, scoring='f1_macro')\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"Naïve Bayes Multinomial (sin TruncatedSVD):\")\n",
    "print(f\"F1-macro scores por fold: {nb_scores}\")\n",
    "print(f\"F1-macro promedio: {nb_scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816ccb03",
   "metadata": {},
   "source": [
    "#### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d19ab87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END ..................C=0.1, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ..................C=0.1, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ..................C=0.1, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END ..................C=0.1, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ..................C=0.1, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=   0.2s\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=   0.3s\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=   0.3s\n",
      "[CV] END ...................C=0.1, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=   0.5s\n",
      "[CV] END ...................C=0.1, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ...................C=0.1, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=   0.3s\n",
      "[CV] END ...................C=0.1, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ...................C=0.1, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=   0.2s\n",
      "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=   0.2s\n",
      "[CV] END ....................C=1, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=   0.3s\n",
      "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=   0.2s\n",
      "[CV] END ....................C=1, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END ....................C=1, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ....................C=1, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END ....................C=1, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=   0.2s\n",
      "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=   0.3s\n",
      "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=   0.2s\n",
      "[CV] END .....................C=1, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=   0.2s\n",
      "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=   0.3s\n",
      "[CV] END .....................C=1, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END .....................C=1, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END .....................C=1, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END .....................C=1, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ........................C=1, gamma=auto, kernel=rbf; total time=   0.2s\n",
      "[CV] END ........................C=1, gamma=auto, kernel=rbf; total time=   0.2s\n",
      "[CV] END ........................C=1, gamma=auto, kernel=rbf; total time=   0.2s\n",
      "[CV] END ........................C=1, gamma=auto, kernel=rbf; total time=   0.2s\n",
      "[CV] END ........................C=1, gamma=auto, kernel=rbf; total time=   0.2s\n",
      "[CV] END ...................C=10, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ...................C=10, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ...................C=10, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END ...................C=10, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ...................C=10, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ......................C=10, gamma=scale, kernel=rbf; total time=   0.3s\n",
      "[CV] END ......................C=10, gamma=scale, kernel=rbf; total time=   0.3s\n",
      "[CV] END ......................C=10, gamma=scale, kernel=rbf; total time=   0.3s\n",
      "[CV] END ......................C=10, gamma=scale, kernel=rbf; total time=   0.3s\n",
      "[CV] END ....................C=10, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ....................C=10, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ......................C=10, gamma=scale, kernel=rbf; total time=   0.2s\n",
      "[CV] END ....................C=10, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ....................C=10, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ....................C=10, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END .......................C=10, gamma=auto, kernel=rbf; total time=   0.2s\n",
      "[CV] END .......................C=10, gamma=auto, kernel=rbf; total time=   0.2s\n",
      "[CV] END .......................C=10, gamma=auto, kernel=rbf; total time=   0.2s\n",
      "[CV] END .......................C=10, gamma=auto, kernel=rbf; total time=   0.2s\n",
      "[CV] END .......................C=10, gamma=auto, kernel=rbf; total time=   0.2s\n",
      "Mejor configuración encontrada:\n",
      "{'C': 10, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Mejor F1-macro: 0.7048\n",
      "\n",
      "Resultados detallados por configuración:\n",
      "{'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'} -> F1-macro: 0.4170 (+/-0.0004)\n",
      "{'C': 0.1, 'gamma': 'scale', 'kernel': 'rbf'} -> F1-macro: 0.4241 (+/-0.0037)\n",
      "{'C': 0.1, 'gamma': 'auto', 'kernel': 'linear'} -> F1-macro: 0.4170 (+/-0.0004)\n",
      "{'C': 0.1, 'gamma': 'auto', 'kernel': 'rbf'} -> F1-macro: 0.4170 (+/-0.0004)\n",
      "{'C': 1, 'gamma': 'scale', 'kernel': 'linear'} -> F1-macro: 0.6204 (+/-0.0073)\n",
      "{'C': 1, 'gamma': 'scale', 'kernel': 'rbf'} -> F1-macro: 0.6788 (+/-0.0196)\n",
      "{'C': 1, 'gamma': 'auto', 'kernel': 'linear'} -> F1-macro: 0.6204 (+/-0.0073)\n",
      "{'C': 1, 'gamma': 'auto', 'kernel': 'rbf'} -> F1-macro: 0.4170 (+/-0.0004)\n",
      "{'C': 10, 'gamma': 'scale', 'kernel': 'linear'} -> F1-macro: 0.7048 (+/-0.0241)\n",
      "{'C': 10, 'gamma': 'scale', 'kernel': 'rbf'} -> F1-macro: 0.7041 (+/-0.0149)\n",
      "{'C': 10, 'gamma': 'auto', 'kernel': 'linear'} -> F1-macro: 0.7048 (+/-0.0241)\n",
      "{'C': 10, 'gamma': 'auto', 'kernel': 'rbf'} -> F1-macro: 0.4481 (+/-0.0137)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, f1_score, make_scorer\n",
    "\n",
    "# Definir el modelo y los hiperparámetros a probar\n",
    "svc = SVC(random_state=0)\n",
    "param_grid = {\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Configurar validación cruzada y búsqueda de hiperparámetros\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "grid_search = GridSearchCV(\n",
    "    svc,\n",
    "    param_grid,\n",
    "    scoring=make_scorer(f1_score, average='macro'),\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Ejecutar búsqueda\n",
    "grid_search.fit(X_train_reduced, train_df['Tag Value'])\n",
    "\n",
    "# Imprimir mejores resultados\n",
    "print(\"Mejor configuración encontrada:\")\n",
    "print(grid_search.best_params_)\n",
    "print(f\"Mejor F1-macro: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "print(\"\\nResultados detallados por configuración:\")\n",
    "means = grid_search.cv_results_['mean_test_score']\n",
    "stds = grid_search.cv_results_['std_test_score']\n",
    "params = grid_search.cv_results_['params']\n",
    "for mean, std, param in zip(means, stds, params):\n",
    "    print(f\"{param} -> F1-macro: {mean:.4f} (+/-{std:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3b14ebbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machines (SVC):\n",
      "F1-macro scores por fold: [0.72859226 0.67157895 0.71005814 0.68562874 0.71975417]\n",
      "F1-macro promedio: 0.7031\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Definir el modelo de SVC\n",
    "svc_model = SVC(C=10,gamma='scale',kernel='linear', random_state=0)\n",
    "\n",
    "# Evaluar el modelo con validación cruzada usando las representaciones reducidas (X_train_reduced)\n",
    "svc_scores = cross_val_score(svc_model, X_train_reduced, train_df['Tag Value'], cv=5, scoring='f1_macro')\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"Support Vector Machines (SVC):\")\n",
    "print(f\"F1-macro scores por fold: {svc_scores}\")\n",
    "print(f\"F1-macro promedio: {svc_scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00becf75",
   "metadata": {},
   "source": [
    "#### Multi-layer Perceptron (MLPClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77984377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.0001, hidden_layer_sizes=(50,), solver=adam; total time=  12.0s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(50,), solver=adam; total time=  12.8s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(50,), solver=adam; total time=  13.8s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(50,), solver=adam; total time=  14.8s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(50,), solver=lbfgs; total time=   1.5s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(50,), solver=lbfgs; total time=   4.5s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(50,), solver=lbfgs; total time=   2.8s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(50,), solver=lbfgs; total time=   3.5s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(50,), solver=lbfgs; total time=   3.6s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(50,), solver=adam; total time=  15.1s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(100,), solver=adam; total time=  15.1s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(100,), solver=adam; total time=  15.9s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(100,), solver=adam; total time=  14.3s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(100,), solver=lbfgs; total time=   5.2s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(100,), solver=lbfgs; total time=   4.6s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(100,), solver=lbfgs; total time=   4.1s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(100,), solver=lbfgs; total time=   3.5s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(100,), solver=adam; total time=  18.9s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(100,), solver=lbfgs; total time=   4.4s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(100, 50), solver=adam; total time=   4.6s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(100,), solver=adam; total time=  17.3s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(100, 50), solver=adam; total time=   5.9s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(100, 50), solver=adam; total time=   6.0s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(100, 50), solver=adam; total time=   6.5s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(100, 50), solver=adam; total time=   6.8s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(100, 50), solver=lbfgs; total time=   9.4s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(100, 50), solver=lbfgs; total time=  11.3s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(100, 50), solver=lbfgs; total time=  13.5s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(100, 50), solver=lbfgs; total time=  10.2s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(100, 50), solver=lbfgs; total time=  20.1s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(150,), solver=adam; total time=  19.1s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(150,), solver=adam; total time=  22.7s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(150,), solver=adam; total time=  18.8s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(150,), solver=lbfgs; total time=   7.3s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(150,), solver=adam; total time=  20.2s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(150,), solver=lbfgs; total time=   5.2s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(150,), solver=adam; total time=  18.1s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(150,), solver=lbfgs; total time=   7.7s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(150,), solver=lbfgs; total time=   6.7s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(150,), solver=lbfgs; total time=   7.6s\n",
      "[CV] END .alpha=0.001, hidden_layer_sizes=(50,), solver=adam; total time=  11.9s\n",
      "[CV] END .alpha=0.001, hidden_layer_sizes=(50,), solver=adam; total time=  12.7s\n",
      "[CV] END .alpha=0.001, hidden_layer_sizes=(50,), solver=adam; total time=  12.7s\n",
      "[CV] END .alpha=0.001, hidden_layer_sizes=(50,), solver=adam; total time=  15.0s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(50,), solver=lbfgs; total time=   5.0s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(50,), solver=lbfgs; total time=   2.7s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(50,), solver=lbfgs; total time=   4.2s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(50,), solver=lbfgs; total time=   5.3s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(50,), solver=lbfgs; total time=   7.6s\n",
      "[CV] END .alpha=0.001, hidden_layer_sizes=(50,), solver=adam; total time=  15.5s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(100,), solver=adam; total time=  13.7s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(100,), solver=adam; total time=  16.1s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(100,), solver=adam; total time=  14.0s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(100,), solver=lbfgs; total time=   8.6s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(100,), solver=lbfgs; total time=   8.1s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(100,), solver=adam; total time=  20.5s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(100,), solver=lbfgs; total time=   7.8s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(100,), solver=adam; total time=  19.0s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(100,), solver=lbfgs; total time=   8.3s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(100,), solver=lbfgs; total time=   8.3s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(100, 50), solver=adam; total time=   6.4s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(100, 50), solver=adam; total time=   5.9s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(100, 50), solver=adam; total time=   5.8s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(100, 50), solver=adam; total time=   6.9s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(100, 50), solver=adam; total time=   6.1s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(100, 50), solver=lbfgs; total time=  10.4s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(100, 50), solver=lbfgs; total time=  10.3s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(100, 50), solver=lbfgs; total time=  14.8s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(100, 50), solver=lbfgs; total time=  20.2s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(150,), solver=adam; total time=  19.5s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(100, 50), solver=lbfgs; total time=  30.6s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(150,), solver=adam; total time=  18.6s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(150,), solver=adam; total time=  16.7s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(150,), solver=adam; total time=  17.3s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(150,), solver=lbfgs; total time=  10.9s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(150,), solver=adam; total time=  22.3s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(150,), solver=lbfgs; total time=  12.5s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(150,), solver=lbfgs; total time=  13.0s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(150,), solver=lbfgs; total time=  12.4s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(150,), solver=lbfgs; total time=  12.4s\n",
      "[CV] END ..alpha=0.01, hidden_layer_sizes=(50,), solver=adam; total time=  13.6s\n",
      "[CV] END ..alpha=0.01, hidden_layer_sizes=(50,), solver=adam; total time=  15.1s\n",
      "[CV] END ..alpha=0.01, hidden_layer_sizes=(50,), solver=adam; total time=  14.4s\n",
      "[CV] END ..alpha=0.01, hidden_layer_sizes=(50,), solver=adam; total time=  16.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .alpha=0.01, hidden_layer_sizes=(50,), solver=lbfgs; total time=  14.3s\n",
      "[CV] END .alpha=0.01, hidden_layer_sizes=(50,), solver=lbfgs; total time=  13.6s\n",
      "[CV] END ..alpha=0.01, hidden_layer_sizes=(50,), solver=adam; total time=  17.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .alpha=0.01, hidden_layer_sizes=(50,), solver=lbfgs; total time=  15.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .alpha=0.01, hidden_layer_sizes=(50,), solver=lbfgs; total time=  16.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .alpha=0.01, hidden_layer_sizes=(50,), solver=lbfgs; total time=  16.7s\n",
      "[CV] END .alpha=0.01, hidden_layer_sizes=(100,), solver=adam; total time=  17.4s\n",
      "[CV] END .alpha=0.01, hidden_layer_sizes=(100,), solver=adam; total time=  14.8s\n",
      "[CV] END .alpha=0.01, hidden_layer_sizes=(100,), solver=adam; total time=  19.4s\n",
      "[CV] END .alpha=0.01, hidden_layer_sizes=(100,), solver=adam; total time=  20.1s\n",
      "[CV] END .alpha=0.01, hidden_layer_sizes=(100,), solver=adam; total time=  18.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, hidden_layer_sizes=(100,), solver=lbfgs; total time=  27.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, hidden_layer_sizes=(100,), solver=lbfgs; total time=  33.1s\n",
      "[CV] END alpha=0.01, hidden_layer_sizes=(100,), solver=lbfgs; total time=  32.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, hidden_layer_sizes=(100,), solver=lbfgs; total time=  32.8s\n",
      "[CV] END alpha=0.01, hidden_layer_sizes=(100, 50), solver=adam; total time=   6.3s\n",
      "[CV] END alpha=0.01, hidden_layer_sizes=(100, 50), solver=adam; total time=   7.1s\n",
      "[CV] END alpha=0.01, hidden_layer_sizes=(100, 50), solver=adam; total time=   8.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, hidden_layer_sizes=(100,), solver=lbfgs; total time=  29.2s\n",
      "[CV] END alpha=0.01, hidden_layer_sizes=(100, 50), solver=adam; total time=   6.4s\n",
      "[CV] END alpha=0.01, hidden_layer_sizes=(100, 50), solver=adam; total time=   7.0s\n",
      "[CV] END alpha=0.01, hidden_layer_sizes=(100, 50), solver=lbfgs; total time=  24.6s\n",
      "[CV] END alpha=0.01, hidden_layer_sizes=(100, 50), solver=lbfgs; total time=  31.8s\n",
      "[CV] END alpha=0.01, hidden_layer_sizes=(100, 50), solver=lbfgs; total time=  37.9s\n",
      "[CV] END alpha=0.01, hidden_layer_sizes=(100, 50), solver=lbfgs; total time=  45.3s\n",
      "[CV] END .alpha=0.01, hidden_layer_sizes=(150,), solver=adam; total time=  20.3s\n",
      "[CV] END .alpha=0.01, hidden_layer_sizes=(150,), solver=adam; total time=  18.5s\n",
      "[CV] END alpha=0.01, hidden_layer_sizes=(100, 50), solver=lbfgs; total time=  29.7s\n",
      "[CV] END .alpha=0.01, hidden_layer_sizes=(150,), solver=adam; total time=  23.2s\n",
      "[CV] END .alpha=0.01, hidden_layer_sizes=(150,), solver=adam; total time=  22.6s\n",
      "[CV] END .alpha=0.01, hidden_layer_sizes=(150,), solver=adam; total time=  22.5s\n",
      "[CV] END alpha=0.01, hidden_layer_sizes=(150,), solver=lbfgs; total time=  28.6s\n",
      "[CV] END alpha=0.01, hidden_layer_sizes=(150,), solver=lbfgs; total time=  44.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, hidden_layer_sizes=(150,), solver=lbfgs; total time=  43.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, hidden_layer_sizes=(150,), solver=lbfgs; total time=  45.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, hidden_layer_sizes=(150,), solver=lbfgs; total time=  34.9s\n",
      "Mejor configuración encontrada:\n",
      "{'alpha': 0.01, 'hidden_layer_sizes': (100,), 'solver': 'adam'}\n",
      "Mejor F1-macro: 0.7230\n",
      "\n",
      "Resultados detallados por configuración:\n",
      "{'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'solver': 'adam'} -> F1-macro: 0.7111 (+/-0.0136)\n",
      "{'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'solver': 'lbfgs'} -> F1-macro: 0.6870 (+/-0.0260)\n",
      "{'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'solver': 'adam'} -> F1-macro: 0.7215 (+/-0.0200)\n",
      "{'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'solver': 'lbfgs'} -> F1-macro: 0.6871 (+/-0.0197)\n",
      "{'alpha': 0.0001, 'hidden_layer_sizes': (100, 50), 'solver': 'adam'} -> F1-macro: 0.6975 (+/-0.0269)\n",
      "{'alpha': 0.0001, 'hidden_layer_sizes': (100, 50), 'solver': 'lbfgs'} -> F1-macro: 0.6783 (+/-0.0189)\n",
      "{'alpha': 0.0001, 'hidden_layer_sizes': (150,), 'solver': 'adam'} -> F1-macro: 0.7147 (+/-0.0264)\n",
      "{'alpha': 0.0001, 'hidden_layer_sizes': (150,), 'solver': 'lbfgs'} -> F1-macro: 0.6786 (+/-0.0217)\n",
      "{'alpha': 0.001, 'hidden_layer_sizes': (50,), 'solver': 'adam'} -> F1-macro: 0.6994 (+/-0.0117)\n",
      "{'alpha': 0.001, 'hidden_layer_sizes': (50,), 'solver': 'lbfgs'} -> F1-macro: 0.6927 (+/-0.0245)\n",
      "{'alpha': 0.001, 'hidden_layer_sizes': (100,), 'solver': 'adam'} -> F1-macro: 0.7212 (+/-0.0200)\n",
      "{'alpha': 0.001, 'hidden_layer_sizes': (100,), 'solver': 'lbfgs'} -> F1-macro: 0.6817 (+/-0.0273)\n",
      "{'alpha': 0.001, 'hidden_layer_sizes': (100, 50), 'solver': 'adam'} -> F1-macro: 0.7006 (+/-0.0251)\n",
      "{'alpha': 0.001, 'hidden_layer_sizes': (100, 50), 'solver': 'lbfgs'} -> F1-macro: 0.6788 (+/-0.0186)\n",
      "{'alpha': 0.001, 'hidden_layer_sizes': (150,), 'solver': 'adam'} -> F1-macro: 0.7188 (+/-0.0246)\n",
      "{'alpha': 0.001, 'hidden_layer_sizes': (150,), 'solver': 'lbfgs'} -> F1-macro: 0.6776 (+/-0.0184)\n",
      "{'alpha': 0.01, 'hidden_layer_sizes': (50,), 'solver': 'adam'} -> F1-macro: 0.7067 (+/-0.0136)\n",
      "{'alpha': 0.01, 'hidden_layer_sizes': (50,), 'solver': 'lbfgs'} -> F1-macro: 0.6952 (+/-0.0138)\n",
      "{'alpha': 0.01, 'hidden_layer_sizes': (100,), 'solver': 'adam'} -> F1-macro: 0.7230 (+/-0.0244)\n",
      "{'alpha': 0.01, 'hidden_layer_sizes': (100,), 'solver': 'lbfgs'} -> F1-macro: 0.6939 (+/-0.0155)\n",
      "{'alpha': 0.01, 'hidden_layer_sizes': (100, 50), 'solver': 'adam'} -> F1-macro: 0.7085 (+/-0.0303)\n",
      "{'alpha': 0.01, 'hidden_layer_sizes': (100, 50), 'solver': 'lbfgs'} -> F1-macro: 0.6859 (+/-0.0208)\n",
      "{'alpha': 0.01, 'hidden_layer_sizes': (150,), 'solver': 'adam'} -> F1-macro: 0.7213 (+/-0.0199)\n",
      "{'alpha': 0.01, 'hidden_layer_sizes': (150,), 'solver': 'lbfgs'} -> F1-macro: 0.7000 (+/-0.0316)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "# Definir el modelo y los hiperparámetros a probar\n",
    "mlp = MLPClassifier(random_state=0, max_iter=2000)\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (100, 50), (150,)],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'solver': ['adam', 'lbfgs'],\n",
    "}\n",
    "\n",
    "# Configurar validación cruzada y búsqueda de hiperparámetros\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "grid_search = GridSearchCV(\n",
    "    mlp,\n",
    "    param_grid,\n",
    "    scoring=make_scorer(f1_score, average='macro'),\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Ejecutar búsqueda\n",
    "grid_search.fit(X_train_reduced, train_df['Tag Value'])\n",
    "\n",
    "# Imprimir mejores resultados\n",
    "print(\"Mejor configuración encontrada:\")\n",
    "print(grid_search.best_params_)\n",
    "print(f\"Mejor F1-macro: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "print(\"\\nResultados detallados por configuración:\")\n",
    "means = grid_search.cv_results_['mean_test_score']\n",
    "stds = grid_search.cv_results_['std_test_score']\n",
    "params = grid_search.cv_results_['params']\n",
    "for mean, std, param in zip(means, stds, params):\n",
    "    print(f\"{param} -> F1-macro: {mean:.4f} (+/-{std:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9812885",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Definir el modelo de MLP\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=2000, alpha=0.01, solver='adam', random_state=0)\n",
    "\n",
    "# Evaluar el modelo con validación cruzada usando las representaciones reducidas (X_train_reduced)\n",
    "mlp_scores = cross_val_score(mlp_model, X_train_reduced, train_df['Tag Value'], cv=5, scoring='f1_macro')\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"Multi-layer Perceptron (MLPClassifier):\")\n",
    "print(f\"F1-macro scores por fold: {mlp_scores}\")\n",
    "print(f\"F1-macro promedio: {mlp_scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242fcb6a",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "770eebf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.6s[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   2.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.2s\n",
      "Mejor configuración encontrada:\n",
      "{'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50}\n",
      "Mejor F1-macro: 0.6510\n",
      "\n",
      "Resultados detallados por configuración:\n",
      "{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50} -> F1-macro: 0.6260 (+/-0.0191)\n",
      "{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100} -> F1-macro: 0.6370 (+/-0.0192)\n",
      "{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200} -> F1-macro: 0.6388 (+/-0.0159)\n",
      "{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50} -> F1-macro: 0.6307 (+/-0.0199)\n",
      "{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100} -> F1-macro: 0.6375 (+/-0.0178)\n",
      "{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200} -> F1-macro: 0.6391 (+/-0.0150)\n",
      "{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50} -> F1-macro: 0.6505 (+/-0.0208)\n",
      "{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100} -> F1-macro: 0.6426 (+/-0.0165)\n",
      "{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200} -> F1-macro: 0.6415 (+/-0.0213)\n",
      "{'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 50} -> F1-macro: 0.6280 (+/-0.0132)\n",
      "{'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100} -> F1-macro: 0.6275 (+/-0.0177)\n",
      "{'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200} -> F1-macro: 0.6323 (+/-0.0118)\n",
      "{'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50} -> F1-macro: 0.6305 (+/-0.0220)\n",
      "{'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100} -> F1-macro: 0.6333 (+/-0.0113)\n",
      "{'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200} -> F1-macro: 0.6270 (+/-0.0191)\n",
      "{'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 50} -> F1-macro: 0.6378 (+/-0.0246)\n",
      "{'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 100} -> F1-macro: 0.6369 (+/-0.0167)\n",
      "{'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200} -> F1-macro: 0.6360 (+/-0.0184)\n",
      "{'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 50} -> F1-macro: 0.6414 (+/-0.0180)\n",
      "{'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100} -> F1-macro: 0.6319 (+/-0.0184)\n",
      "{'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200} -> F1-macro: 0.6249 (+/-0.0154)\n",
      "{'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 50} -> F1-macro: 0.6414 (+/-0.0180)\n",
      "{'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 100} -> F1-macro: 0.6319 (+/-0.0184)\n",
      "{'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 200} -> F1-macro: 0.6249 (+/-0.0154)\n",
      "{'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 50} -> F1-macro: 0.6375 (+/-0.0181)\n",
      "{'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100} -> F1-macro: 0.6306 (+/-0.0144)\n",
      "{'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 200} -> F1-macro: 0.6236 (+/-0.0152)\n",
      "{'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50} -> F1-macro: 0.6117 (+/-0.0182)\n",
      "{'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100} -> F1-macro: 0.6181 (+/-0.0189)\n",
      "{'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200} -> F1-macro: 0.6196 (+/-0.0145)\n",
      "{'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50} -> F1-macro: 0.6218 (+/-0.0202)\n",
      "{'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100} -> F1-macro: 0.6163 (+/-0.0173)\n",
      "{'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200} -> F1-macro: 0.6204 (+/-0.0161)\n",
      "{'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50} -> F1-macro: 0.6211 (+/-0.0139)\n",
      "{'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100} -> F1-macro: 0.6161 (+/-0.0189)\n",
      "{'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200} -> F1-macro: 0.6187 (+/-0.0128)\n",
      "{'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 50} -> F1-macro: 0.6223 (+/-0.0160)\n",
      "{'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100} -> F1-macro: 0.6150 (+/-0.0161)\n",
      "{'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200} -> F1-macro: 0.6211 (+/-0.0201)\n",
      "{'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50} -> F1-macro: 0.6094 (+/-0.0158)\n",
      "{'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100} -> F1-macro: 0.6154 (+/-0.0175)\n",
      "{'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200} -> F1-macro: 0.6167 (+/-0.0172)\n",
      "{'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 50} -> F1-macro: 0.6151 (+/-0.0244)\n",
      "{'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 100} -> F1-macro: 0.6173 (+/-0.0094)\n",
      "{'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200} -> F1-macro: 0.6147 (+/-0.0148)\n",
      "{'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 50} -> F1-macro: 0.6180 (+/-0.0145)\n",
      "{'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100} -> F1-macro: 0.6067 (+/-0.0234)\n",
      "{'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200} -> F1-macro: 0.6079 (+/-0.0095)\n",
      "{'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 50} -> F1-macro: 0.6180 (+/-0.0145)\n",
      "{'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 100} -> F1-macro: 0.6067 (+/-0.0234)\n",
      "{'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 200} -> F1-macro: 0.6079 (+/-0.0095)\n",
      "{'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 50} -> F1-macro: 0.6205 (+/-0.0162)\n",
      "{'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100} -> F1-macro: 0.6155 (+/-0.0156)\n",
      "{'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 200} -> F1-macro: 0.6155 (+/-0.0153)\n",
      "{'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50} -> F1-macro: 0.6276 (+/-0.0165)\n",
      "{'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100} -> F1-macro: 0.6425 (+/-0.0173)\n",
      "{'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200} -> F1-macro: 0.6359 (+/-0.0138)\n",
      "{'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50} -> F1-macro: 0.6412 (+/-0.0179)\n",
      "{'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100} -> F1-macro: 0.6307 (+/-0.0211)\n",
      "{'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200} -> F1-macro: 0.6375 (+/-0.0160)\n",
      "{'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50} -> F1-macro: 0.6425 (+/-0.0195)\n",
      "{'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100} -> F1-macro: 0.6401 (+/-0.0195)\n",
      "{'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200} -> F1-macro: 0.6398 (+/-0.0161)\n",
      "{'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 50} -> F1-macro: 0.6294 (+/-0.0081)\n",
      "{'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100} -> F1-macro: 0.6287 (+/-0.0181)\n",
      "{'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200} -> F1-macro: 0.6337 (+/-0.0147)\n",
      "{'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50} -> F1-macro: 0.6303 (+/-0.0188)\n",
      "{'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100} -> F1-macro: 0.6389 (+/-0.0140)\n",
      "{'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200} -> F1-macro: 0.6290 (+/-0.0178)\n",
      "{'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 50} -> F1-macro: 0.6416 (+/-0.0174)\n",
      "{'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 100} -> F1-macro: 0.6411 (+/-0.0147)\n",
      "{'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200} -> F1-macro: 0.6319 (+/-0.0139)\n",
      "{'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 50} -> F1-macro: 0.6344 (+/-0.0160)\n",
      "{'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100} -> F1-macro: 0.6319 (+/-0.0184)\n",
      "{'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200} -> F1-macro: 0.6233 (+/-0.0131)\n",
      "{'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 50} -> F1-macro: 0.6344 (+/-0.0160)\n",
      "{'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 100} -> F1-macro: 0.6319 (+/-0.0184)\n",
      "{'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 200} -> F1-macro: 0.6233 (+/-0.0131)\n",
      "{'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 50} -> F1-macro: 0.6408 (+/-0.0163)\n",
      "{'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100} -> F1-macro: 0.6317 (+/-0.0160)\n",
      "{'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 200} -> F1-macro: 0.6284 (+/-0.0122)\n",
      "{'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50} -> F1-macro: 0.6282 (+/-0.0215)\n",
      "{'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100} -> F1-macro: 0.6366 (+/-0.0197)\n",
      "{'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200} -> F1-macro: 0.6395 (+/-0.0178)\n",
      "{'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50} -> F1-macro: 0.6308 (+/-0.0198)\n",
      "{'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100} -> F1-macro: 0.6395 (+/-0.0177)\n",
      "{'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200} -> F1-macro: 0.6402 (+/-0.0155)\n",
      "{'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50} -> F1-macro: 0.6510 (+/-0.0214)\n",
      "{'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100} -> F1-macro: 0.6422 (+/-0.0169)\n",
      "{'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200} -> F1-macro: 0.6431 (+/-0.0202)\n",
      "{'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 50} -> F1-macro: 0.6280 (+/-0.0132)\n",
      "{'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100} -> F1-macro: 0.6275 (+/-0.0177)\n",
      "{'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200} -> F1-macro: 0.6323 (+/-0.0118)\n",
      "{'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50} -> F1-macro: 0.6305 (+/-0.0220)\n",
      "{'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100} -> F1-macro: 0.6333 (+/-0.0113)\n",
      "{'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200} -> F1-macro: 0.6270 (+/-0.0191)\n",
      "{'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 50} -> F1-macro: 0.6378 (+/-0.0246)\n",
      "{'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 100} -> F1-macro: 0.6369 (+/-0.0167)\n",
      "{'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200} -> F1-macro: 0.6360 (+/-0.0184)\n",
      "{'max_depth': 30, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 50} -> F1-macro: 0.6414 (+/-0.0180)\n",
      "{'max_depth': 30, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100} -> F1-macro: 0.6319 (+/-0.0184)\n",
      "{'max_depth': 30, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200} -> F1-macro: 0.6249 (+/-0.0154)\n",
      "{'max_depth': 30, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 50} -> F1-macro: 0.6414 (+/-0.0180)\n",
      "{'max_depth': 30, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 100} -> F1-macro: 0.6319 (+/-0.0184)\n",
      "{'max_depth': 30, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 200} -> F1-macro: 0.6249 (+/-0.0154)\n",
      "{'max_depth': 30, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 50} -> F1-macro: 0.6375 (+/-0.0181)\n",
      "{'max_depth': 30, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100} -> F1-macro: 0.6306 (+/-0.0144)\n",
      "{'max_depth': 30, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 200} -> F1-macro: 0.6236 (+/-0.0152)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "# Definir el modelo y los hiperparámetros a probar\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Configurar validación cruzada y búsqueda de hiperparámetros\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "grid_search = GridSearchCV(\n",
    "    rf,\n",
    "    param_grid,\n",
    "    scoring=make_scorer(f1_score, average='macro'),\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Ejecutar búsqueda\n",
    "grid_search.fit(X_train_reduced, train_df['Tag Value'])\n",
    "\n",
    "# Imprimir mejores resultados\n",
    "print(\"Mejor configuración encontrada:\")\n",
    "print(grid_search.best_params_)\n",
    "print(f\"Mejor F1-macro: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "print(\"\\nResultados detallados por configuración:\")\n",
    "means = grid_search.cv_results_['mean_test_score']\n",
    "stds = grid_search.cv_results_['std_test_score']\n",
    "params = grid_search.cv_results_['params']\n",
    "for mean, std, param in zip(means, stds, params):\n",
    "    print(f\"{param} -> F1-macro: {mean:.4f} (+/-{std:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ce05bca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "F1-macro scores por fold: [0.66965786 0.60441819 0.63211679 0.64269706 0.64793972]\n",
      "F1-macro promedio: 0.6394\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Definir el modelo de Random Forest\n",
    "rf_model = RandomForestClassifier(max_depth=30, min_samples_leaf=1, min_samples_split=10,n_estimators=50, random_state=0)\n",
    "\n",
    "# Evaluar el modelo con validación cruzada usando las representaciones reducidas (X_train_reduced)\n",
    "rf_scores = cross_val_score(rf_model, X_train_reduced, train_df['Tag Value'], cv=5, scoring='f1_macro')\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"Random Forest:\")\n",
    "print(f\"F1-macro scores por fold: {rf_scores}\")\n",
    "print(f\"F1-macro promedio: {rf_scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163749c1",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c60263a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=50, subsample=0.8; total time=   2.0s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=50, subsample=0.8; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=50, subsample=0.8; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=50, subsample=0.8; total time=   2.1s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=50, subsample=0.8; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=50, subsample=1.0; total time=   2.3s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=50, subsample=1.0; total time=   2.4s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=50, subsample=1.0; total time=   2.3s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=50, subsample=1.0; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=50, subsample=1.0; total time=   2.4s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=100, subsample=0.8; total time=   3.5s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=100, subsample=0.8; total time=   3.6s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=100, subsample=0.8; total time=   3.5s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=100, subsample=0.8; total time=   3.7s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=100, subsample=0.8; total time=   3.5s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=100, subsample=1.0; total time=   4.5s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=100, subsample=1.0; total time=   4.5s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=100, subsample=1.0; total time=   4.5s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=100, subsample=1.0; total time=   4.5s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=100, subsample=1.0; total time=   4.5s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=200, subsample=0.8; total time=   7.3s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=200, subsample=0.8; total time=   7.2s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=200, subsample=0.8; total time=   7.1s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=200, subsample=0.8; total time=   7.1s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=200, subsample=0.8; total time=   7.2s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=200, subsample=1.0; total time=   9.1s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=200, subsample=1.0; total time=   9.0s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=200, subsample=1.0; total time=   9.2s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=50, subsample=0.8; total time=   2.6s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=50, subsample=0.8; total time=   2.8s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=50, subsample=0.8; total time=   2.7s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=200, subsample=1.0; total time=   9.2s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=50, subsample=0.8; total time=   2.8s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=50, subsample=0.8; total time=   2.7s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=200, subsample=1.0; total time=   9.2s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=50, subsample=1.0; total time=   3.3s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=50, subsample=1.0; total time=   3.5s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=50, subsample=1.0; total time=   3.4s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=50, subsample=1.0; total time=   3.6s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=50, subsample=1.0; total time=   3.4s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   5.5s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   5.4s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   5.5s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   5.6s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   5.5s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   6.8s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   6.9s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   6.8s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   6.9s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   7.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=  11.0s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=  11.0s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=  10.8s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=  10.9s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=  11.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=  14.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=  13.8s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=  14.3s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=50, subsample=0.8; total time=   4.6s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=50, subsample=0.8; total time=   4.5s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=  14.2s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=50, subsample=0.8; total time=   4.6s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=  14.1s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=50, subsample=0.8; total time=   4.6s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=50, subsample=0.8; total time=   4.5s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=50, subsample=1.0; total time=   5.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=50, subsample=1.0; total time=   5.7s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=50, subsample=1.0; total time=   6.0s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=50, subsample=1.0; total time=   5.7s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=50, subsample=1.0; total time=   6.0s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   9.3s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   9.2s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   9.2s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   9.1s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   9.1s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=  11.5s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=  11.7s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=  11.5s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=  11.4s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=  11.7s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=  18.7s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=  18.3s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=  18.2s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=  18.2s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=  18.6s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=  22.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=  23.0s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=50, subsample=0.8; total time=   2.0s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=50, subsample=0.8; total time=   1.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=  23.5s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=50, subsample=0.8; total time=   2.1s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=50, subsample=0.8; total time=   2.0s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=50, subsample=0.8; total time=   2.0s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=50, subsample=1.0; total time=   2.6s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=50, subsample=1.0; total time=   2.5s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=50, subsample=1.0; total time=   2.6s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=  23.8s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=50, subsample=1.0; total time=   2.5s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=50, subsample=1.0; total time=   2.6s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=100, subsample=0.8; total time=   4.1s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=100, subsample=0.8; total time=   3.9s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=100, subsample=0.8; total time=   3.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=  23.7s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=100, subsample=0.8; total time=   4.2s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=100, subsample=0.8; total time=   4.1s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=100, subsample=1.0; total time=   5.0s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=100, subsample=1.0; total time=   5.0s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=100, subsample=1.0; total time=   5.2s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=100, subsample=1.0; total time=   5.2s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=100, subsample=1.0; total time=   5.1s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=200, subsample=0.8; total time=   8.0s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=200, subsample=0.8; total time=   8.0s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=200, subsample=0.8; total time=   8.0s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=200, subsample=0.8; total time=   7.9s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=200, subsample=0.8; total time=   8.0s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=200, subsample=1.0; total time=  10.9s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=200, subsample=1.0; total time=  10.9s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=200, subsample=1.0; total time=  11.3s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=50, subsample=0.8; total time=   3.9s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=50, subsample=0.8; total time=   3.1s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=200, subsample=1.0; total time=  11.2s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=50, subsample=0.8; total time=   3.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=50, subsample=0.8; total time=   2.9s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=50, subsample=0.8; total time=   3.0s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=200, subsample=1.0; total time=  11.2s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=50, subsample=1.0; total time=   4.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=50, subsample=1.0; total time=   4.0s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=50, subsample=1.0; total time=   3.8s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=50, subsample=1.0; total time=   3.6s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=50, subsample=1.0; total time=   3.9s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=100, subsample=0.8; total time=   5.7s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=100, subsample=0.8; total time=   5.8s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=100, subsample=0.8; total time=   6.0s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=100, subsample=0.8; total time=   5.9s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=100, subsample=0.8; total time=   6.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=100, subsample=1.0; total time=   7.4s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=100, subsample=1.0; total time=   7.5s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=100, subsample=1.0; total time=   7.8s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=100, subsample=1.0; total time=   7.4s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=100, subsample=1.0; total time=   7.7s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.8; total time=  11.7s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.8; total time=  11.8s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.8; total time=  11.8s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.8; total time=  12.0s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.8; total time=  11.7s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=200, subsample=1.0; total time=  15.5s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=200, subsample=1.0; total time=  15.0s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=200, subsample=1.0; total time=  14.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=50, subsample=0.8; total time=   4.7s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=50, subsample=0.8; total time=   4.7s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=200, subsample=1.0; total time=  15.0s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=50, subsample=0.8; total time=   4.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=50, subsample=0.8; total time=   5.0s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=200, subsample=1.0; total time=  15.2s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=50, subsample=0.8; total time=   4.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=50, subsample=1.0; total time=   6.1s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=50, subsample=1.0; total time=   6.0s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=50, subsample=1.0; total time=   6.2s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=50, subsample=1.0; total time=   6.0s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=50, subsample=1.0; total time=   6.1s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.8; total time=   9.6s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.8; total time=   9.7s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.8; total time=   9.4s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.8; total time=   9.4s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.8; total time=   9.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=100, subsample=1.0; total time=  12.1s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=100, subsample=1.0; total time=  12.0s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=100, subsample=1.0; total time=  11.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=100, subsample=1.0; total time=  12.1s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=100, subsample=1.0; total time=  12.3s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.8; total time=  18.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.8; total time=  19.3s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.8; total time=  19.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.8; total time=  18.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.8; total time=  19.1s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=200, subsample=1.0; total time=  24.7s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=200, subsample=1.0; total time=  24.4s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=50, subsample=0.8; total time=   2.0s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=200, subsample=1.0; total time=  25.1s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=50, subsample=0.8; total time=   2.2s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=50, subsample=0.8; total time=   2.2s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=50, subsample=0.8; total time=   2.0s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=50, subsample=0.8; total time=   2.1s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=50, subsample=1.0; total time=   2.7s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=200, subsample=1.0; total time=  24.3s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=50, subsample=1.0; total time=   2.7s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=50, subsample=1.0; total time=   2.7s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=50, subsample=1.0; total time=   2.6s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=50, subsample=1.0; total time=   2.7s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=100, subsample=0.8; total time=   4.1s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=100, subsample=0.8; total time=   4.1s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=100, subsample=0.8; total time=   4.2s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=200, subsample=1.0; total time=  24.9s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=100, subsample=0.8; total time=   4.1s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=100, subsample=0.8; total time=   4.0s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=100, subsample=1.0; total time=   5.4s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=100, subsample=1.0; total time=   5.6s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=100, subsample=1.0; total time=   5.4s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=100, subsample=1.0; total time=   5.2s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=100, subsample=1.0; total time=   5.2s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=200, subsample=0.8; total time=   8.5s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=200, subsample=0.8; total time=   8.0s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=200, subsample=0.8; total time=   8.3s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=200, subsample=0.8; total time=   8.5s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=200, subsample=0.8; total time=   8.2s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=200, subsample=1.0; total time=  10.4s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=200, subsample=1.0; total time=  10.4s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=200, subsample=1.0; total time=  10.4s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=50, subsample=0.8; total time=   3.2s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=50, subsample=0.8; total time=   3.0s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=50, subsample=0.8; total time=   3.1s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=200, subsample=1.0; total time=  10.7s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=50, subsample=0.8; total time=   2.9s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=50, subsample=0.8; total time=   3.2s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=200, subsample=1.0; total time=  10.4s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=50, subsample=1.0; total time=   4.0s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=50, subsample=1.0; total time=   3.9s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=50, subsample=1.0; total time=   4.0s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=50, subsample=1.0; total time=   3.8s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=50, subsample=1.0; total time=   4.0s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   5.9s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   6.1s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   6.0s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   6.2s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   6.1s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   7.7s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   7.6s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   7.8s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   8.0s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   7.9s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=  12.1s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=  12.4s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=  12.1s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=  12.0s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=  11.9s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=  15.1s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=  15.2s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=  15.6s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=50, subsample=0.8; total time=   4.6s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=  15.6s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=50, subsample=0.8; total time=   4.9s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=50, subsample=0.8; total time=   4.6s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=50, subsample=0.8; total time=   4.9s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=50, subsample=0.8; total time=   4.8s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=  16.0s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=50, subsample=1.0; total time=   6.0s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=50, subsample=1.0; total time=   6.1s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=50, subsample=1.0; total time=   6.2s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=50, subsample=1.0; total time=   6.0s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=50, subsample=1.0; total time=   6.1s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   9.7s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   9.5s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   9.9s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   9.2s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   9.9s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=  12.3s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=  12.2s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=  12.1s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=  12.3s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=  12.4s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=  19.7s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=  19.1s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=  19.3s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=  19.2s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=  19.5s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=  24.4s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=  25.0s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=  24.3s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=  23.5s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=  22.4s\n",
      "Mejor configuración encontrada:\n",
      "{'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Mejor F1-macro: 0.6992\n",
      "\n",
      "Resultados detallados por configuración:\n",
      "{'learning_rate': 0.01, 'max_depth': 2, 'n_estimators': 50, 'subsample': 0.8} -> F1-macro: 0.5368 (+/-0.0223)\n",
      "{'learning_rate': 0.01, 'max_depth': 2, 'n_estimators': 50, 'subsample': 1.0} -> F1-macro: 0.5362 (+/-0.0219)\n",
      "{'learning_rate': 0.01, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.8} -> F1-macro: 0.5558 (+/-0.0228)\n",
      "{'learning_rate': 0.01, 'max_depth': 2, 'n_estimators': 100, 'subsample': 1.0} -> F1-macro: 0.5548 (+/-0.0243)\n",
      "{'learning_rate': 0.01, 'max_depth': 2, 'n_estimators': 200, 'subsample': 0.8} -> F1-macro: 0.5877 (+/-0.0317)\n",
      "{'learning_rate': 0.01, 'max_depth': 2, 'n_estimators': 200, 'subsample': 1.0} -> F1-macro: 0.5859 (+/-0.0305)\n",
      "{'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50, 'subsample': 0.8} -> F1-macro: 0.5326 (+/-0.0169)\n",
      "{'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50, 'subsample': 1.0} -> F1-macro: 0.5463 (+/-0.0236)\n",
      "{'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.8} -> F1-macro: 0.5632 (+/-0.0259)\n",
      "{'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100, 'subsample': 1.0} -> F1-macro: 0.5716 (+/-0.0229)\n",
      "{'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200, 'subsample': 0.8} -> F1-macro: 0.6216 (+/-0.0113)\n",
      "{'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200, 'subsample': 1.0} -> F1-macro: 0.6255 (+/-0.0142)\n",
      "{'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 50, 'subsample': 0.8} -> F1-macro: 0.5324 (+/-0.0164)\n",
      "{'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 50, 'subsample': 1.0} -> F1-macro: 0.5481 (+/-0.0301)\n",
      "{'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.8} -> F1-macro: 0.5961 (+/-0.0119)\n",
      "{'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 100, 'subsample': 1.0} -> F1-macro: 0.5973 (+/-0.0228)\n",
      "{'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 200, 'subsample': 0.8} -> F1-macro: 0.6488 (+/-0.0082)\n",
      "{'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 200, 'subsample': 1.0} -> F1-macro: 0.6383 (+/-0.0209)\n",
      "{'learning_rate': 0.05, 'max_depth': 2, 'n_estimators': 50, 'subsample': 0.8} -> F1-macro: 0.6026 (+/-0.0200)\n",
      "{'learning_rate': 0.05, 'max_depth': 2, 'n_estimators': 50, 'subsample': 1.0} -> F1-macro: 0.6043 (+/-0.0282)\n",
      "{'learning_rate': 0.05, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.8} -> F1-macro: 0.6408 (+/-0.0078)\n",
      "{'learning_rate': 0.05, 'max_depth': 2, 'n_estimators': 100, 'subsample': 1.0} -> F1-macro: 0.6372 (+/-0.0147)\n",
      "{'learning_rate': 0.05, 'max_depth': 2, 'n_estimators': 200, 'subsample': 0.8} -> F1-macro: 0.6686 (+/-0.0130)\n",
      "{'learning_rate': 0.05, 'max_depth': 2, 'n_estimators': 200, 'subsample': 1.0} -> F1-macro: 0.6636 (+/-0.0105)\n",
      "{'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 50, 'subsample': 0.8} -> F1-macro: 0.6402 (+/-0.0151)\n",
      "{'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 50, 'subsample': 1.0} -> F1-macro: 0.6395 (+/-0.0108)\n",
      "{'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.8} -> F1-macro: 0.6683 (+/-0.0083)\n",
      "{'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 100, 'subsample': 1.0} -> F1-macro: 0.6609 (+/-0.0109)\n",
      "{'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 200, 'subsample': 0.8} -> F1-macro: 0.6857 (+/-0.0119)\n",
      "{'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 200, 'subsample': 1.0} -> F1-macro: 0.6798 (+/-0.0079)\n",
      "{'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 50, 'subsample': 0.8} -> F1-macro: 0.6597 (+/-0.0160)\n",
      "{'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 50, 'subsample': 1.0} -> F1-macro: 0.6651 (+/-0.0134)\n",
      "{'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.8} -> F1-macro: 0.6789 (+/-0.0128)\n",
      "{'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 100, 'subsample': 1.0} -> F1-macro: 0.6812 (+/-0.0061)\n",
      "{'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 200, 'subsample': 0.8} -> F1-macro: 0.6833 (+/-0.0132)\n",
      "{'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 200, 'subsample': 1.0} -> F1-macro: 0.6939 (+/-0.0169)\n",
      "{'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 50, 'subsample': 0.8} -> F1-macro: 0.6517 (+/-0.0084)\n",
      "{'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 50, 'subsample': 1.0} -> F1-macro: 0.6404 (+/-0.0117)\n",
      "{'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.8} -> F1-macro: 0.6805 (+/-0.0194)\n",
      "{'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 100, 'subsample': 1.0} -> F1-macro: 0.6597 (+/-0.0128)\n",
      "{'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 200, 'subsample': 0.8} -> F1-macro: 0.6926 (+/-0.0164)\n",
      "{'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 200, 'subsample': 1.0} -> F1-macro: 0.6792 (+/-0.0188)\n",
      "{'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50, 'subsample': 0.8} -> F1-macro: 0.6700 (+/-0.0213)\n",
      "{'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50, 'subsample': 1.0} -> F1-macro: 0.6644 (+/-0.0104)\n",
      "{'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.8} -> F1-macro: 0.6903 (+/-0.0187)\n",
      "{'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 1.0} -> F1-macro: 0.6827 (+/-0.0133)\n",
      "{'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'subsample': 0.8} -> F1-macro: 0.6940 (+/-0.0260)\n",
      "{'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'subsample': 1.0} -> F1-macro: 0.6954 (+/-0.0179)\n",
      "{'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 50, 'subsample': 0.8} -> F1-macro: 0.6837 (+/-0.0196)\n",
      "{'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 50, 'subsample': 1.0} -> F1-macro: 0.6860 (+/-0.0123)\n",
      "{'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.8} -> F1-macro: 0.6801 (+/-0.0146)\n",
      "{'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100, 'subsample': 1.0} -> F1-macro: 0.6903 (+/-0.0155)\n",
      "{'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200, 'subsample': 0.8} -> F1-macro: 0.6938 (+/-0.0229)\n",
      "{'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200, 'subsample': 1.0} -> F1-macro: 0.6992 (+/-0.0171)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "# Definir el modelo y los hiperparámetros a probar\n",
    "gb = GradientBoostingClassifier(random_state=0)\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [2, 3, 5],\n",
    "    'subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Configurar validación cruzada y búsqueda de hiperparámetros\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "grid_search = GridSearchCV(\n",
    "    gb,\n",
    "    param_grid,\n",
    "    scoring=make_scorer(f1_score, average='macro'),\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Ejecutar búsqueda\n",
    "grid_search.fit(X_train_reduced, train_df['Tag Value'])\n",
    "\n",
    "# Imprimir mejores resultados\n",
    "print(\"Mejor configuración encontrada:\")\n",
    "print(grid_search.best_params_)\n",
    "print(f\"Mejor F1-macro: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "print(\"\\nResultados detallados por configuración:\")\n",
    "means = grid_search.cv_results_['mean_test_score']\n",
    "stds = grid_search.cv_results_['std_test_score']\n",
    "params = grid_search.cv_results_['params']\n",
    "for mean, std, param in zip(means, stds, params):\n",
    "    print(f\"{param} -> F1-macro: {mean:.4f} (+/-{std:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1a4cabe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting:\n",
      "F1-macro scores por fold: [0.67592593 0.63653528 0.67474747 0.67921518 0.66369586]\n",
      "F1-macro promedio: 0.6660\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Definir el modelo de Gradient Boosting\n",
    "gb_model = GradientBoostingClassifier(subsample=1.0,n_estimators=200, learning_rate=0.1, max_depth=5, random_state=0)\n",
    "\n",
    "# Evaluar el modelo con validación cruzada usando las representaciones reducidas (X_train_reduced)\n",
    "gb_scores = cross_val_score(gb_model, X_train_reduced, train_df['Tag Value'], cv=5, scoring='f1_macro')\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"Gradient Boosting:\")\n",
    "print(f\"F1-macro scores por fold: {gb_scores}\")\n",
    "print(f\"F1-macro promedio: {gb_scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b8c545",
   "metadata": {},
   "source": [
    "## Usando texto limpio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27f58f7",
   "metadata": {},
   "source": [
    "## Usando no-stopwrods"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
