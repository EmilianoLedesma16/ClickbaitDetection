{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d03c804",
   "metadata": {},
   "source": [
    "# Entranamiento de modelos usando tokenizacion + cleaning + no stop words + lematización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6878b260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Tweet ID', 'Teaser Text', 'Tag Value', 'tokenized_text',\n",
      "       'cleaned_text', 'no_stopwords_text', 'lemmatized_text',\n",
      "       'tokenized_cleaned_text', 'tokenized_cleaned_text_no_stopwords',\n",
      "       'tokenized_cleaned_text_no_stopwords_lemmatized'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar los conjuntos de entrenamiento y desarrollo\n",
    "train_df = pd.read_csv(\"../data/TA1C_dataset_detection_train_split.csv\")\n",
    "dev_df = pd.read_csv(\"../data/TA1C_dataset_detection_dev_split.csv\")\n",
    "\n",
    "# Verificar las columnas disponibles\n",
    "print(train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa878715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuración: ngram_range=(1, 1), representación=tfidf\n",
      "Dimensiones de X_train: (2100, 9008)\n",
      "Dimensiones de X_dev: (700, 9008)\n",
      "Configuración: ngram_range=(1, 2), representación=tfidf\n",
      "Dimensiones de X_train: (2100, 30722)\n",
      "Dimensiones de X_dev: (700, 30722)\n",
      "Configuración: ngram_range=(1, 3), representación=tfidf\n",
      "Dimensiones de X_train: (2100, 51738)\n",
      "Dimensiones de X_dev: (700, 51738)\n",
      "Configuración: ngram_range=(1, 2), representación=binary\n",
      "Dimensiones de X_train: (2100, 30722)\n",
      "Dimensiones de X_dev: (700, 30722)\n",
      "Configuración: ngram_range=(1, 2), representación=frequency\n",
      "Dimensiones de X_train: (2100, 30722)\n",
      "Dimensiones de X_dev: (700, 30722)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Probar diferentes configuraciones de n-gramas y representaciones\n",
    "configurations = [\n",
    "    {\"ngram_range\": (1, 1), \"representation\": \"tfidf\"},  # Unigramas con TF-IDF\n",
    "    {\"ngram_range\": (1, 2), \"representation\": \"tfidf\"},  # Unigramas + Bigramas con TF-IDF\n",
    "    {\"ngram_range\": (1, 3), \"representation\": \"tfidf\"},  # Unigramas + Bigramas + Trigramas con TF-IDF\n",
    "    {\"ngram_range\": (1, 2), \"representation\": \"binary\"},  # Unigramas + Bigramas con representación binaria\n",
    "    {\"ngram_range\": (1, 2), \"representation\": \"frequency\"},  # Unigramas + Bigramas con frecuencia\n",
    "]\n",
    "\n",
    "for config in configurations:\n",
    "    print(f\"Configuración: ngram_range={config['ngram_range']}, representación={config['representation']}\")\n",
    "    \n",
    "    # Configurar el vectorizador\n",
    "    if config[\"representation\"] == \"tfidf\":\n",
    "        vectorizer = TfidfVectorizer(ngram_range=config[\"ngram_range\"])\n",
    "    elif config[\"representation\"] == \"binary\":\n",
    "        vectorizer = TfidfVectorizer(ngram_range=config[\"ngram_range\"], binary=True)\n",
    "    elif config[\"representation\"] == \"frequency\":\n",
    "        vectorizer = TfidfVectorizer(ngram_range=config[\"ngram_range\"], use_idf=False)\n",
    "    \n",
    "    # Crear representaciones para el conjunto de entrenamiento y desarrollo\n",
    "    X_train = vectorizer.fit_transform(train_df['tokenized_cleaned_text_no_stopwords_lemmatized'])\n",
    "    X_dev = vectorizer.transform(dev_df['tokenized_cleaned_text_no_stopwords_lemmatized'])\n",
    "    \n",
    "    # Verificar las dimensiones\n",
    "    print(f\"Dimensiones de X_train: {X_train.shape}\")\n",
    "    print(f\"Dimensiones de X_dev: {X_dev.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f703cf8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones reducidas de X_train: (2100, 100)\n",
      "Dimensiones reducidas de X_dev: (700, 100)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Reducir dimensionalidad con TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=100, random_state=0)  # Reducir a 100 dimensiones\n",
    "X_train_reduced = svd.fit_transform(X_train)\n",
    "X_dev_reduced = svd.transform(X_dev)\n",
    "\n",
    "# Verificar las dimensiones después de la reducción\n",
    "print(f\"Dimensiones reducidas de X_train: {X_train_reduced.shape}\")\n",
    "print(f\"Dimensiones reducidas de X_dev: {X_dev_reduced.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdaa0926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir etiquetas de texto a valores numéricos\n",
    "label_mapping = {'Clickbait': 1, 'No': 0}\n",
    "train_df['Tag Value'] = train_df['Tag Value'].map(label_mapping)\n",
    "dev_df['Tag Value'] = dev_df['Tag Value'].map(label_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b25d38",
   "metadata": {},
   "source": [
    "## Logistic Regression y Validación Cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0383e1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-macro scores por fold: [0.42551064 0.41666667 0.41666667 0.41747573 0.41666667]\n",
      "F1-macro promedio: 0.4186\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "# Configurar validación cruzada estratificada\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# Definir el modelo\n",
    "model = LogisticRegression(max_iter=200)\n",
    "\n",
    "# Evaluar el modelo con validación cruzada usando f1_macro\n",
    "f1_macro_scorer = make_scorer(f1_score, average='macro')\n",
    "scores = cross_val_score(model, X_train_reduced, train_df['Tag Value'], cv=cv, scoring=f1_macro_scorer)\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(f\"F1-macro scores por fold: {scores}\")\n",
    "print(f\"F1-macro promedio: {scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7badadf0",
   "metadata": {},
   "source": [
    "## Naive Bayes Multinominal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1da1759c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naïve Bayes Multinomial (sin TruncatedSVD):\n",
      "F1-macro scores por fold: [0.41666667 0.41666667 0.41666667 0.41747573 0.41747573]\n",
      "F1-macro promedio: 0.4170\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Definir el modelo de Naïve Bayes Multinomial\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "# Evaluar el modelo con validación cruzada usando las representaciones originales (X_train)\n",
    "nb_scores = cross_val_score(nb_model, X_train, train_df['Tag Value'], cv=5, scoring='f1_macro')\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"Naïve Bayes Multinomial (sin TruncatedSVD):\")\n",
    "print(f\"F1-macro scores por fold: {nb_scores}\")\n",
    "print(f\"F1-macro promedio: {nb_scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38189668",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "589b0336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END ..................C=0.1, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ..................C=0.1, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ..................C=0.1, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ..................C=0.1, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ..................C=0.1, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=   0.2s\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=   0.3s\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=   0.2s\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=   0.2s\n",
      "[CV] END ...................C=0.1, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ...................C=0.1, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END .....................C=0.1, gamma=scale, kernel=rbf; total time=   0.2s\n",
      "[CV] END ...................C=0.1, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ...................C=0.1, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ...................C=0.1, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=   0.2s\n",
      "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=   0.2s\n",
      "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=   0.2s\n",
      "[CV] END ......................C=0.1, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ....................C=1, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ....................C=1, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ....................C=1, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END ....................C=1, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ....................C=1, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=   0.2s\n",
      "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=   0.2s\n",
      "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=   0.2s\n",
      "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=   0.2s\n",
      "[CV] END .....................C=1, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END .....................C=1, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END .....................C=1, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END .......................C=1, gamma=scale, kernel=rbf; total time=   0.2s\n",
      "[CV] END .....................C=1, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END .....................C=1, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ........................C=1, gamma=auto, kernel=rbf; total time=   0.2s\n",
      "[CV] END ........................C=1, gamma=auto, kernel=rbf; total time=   0.2s\n",
      "[CV] END ........................C=1, gamma=auto, kernel=rbf; total time=   0.2s\n",
      "[CV] END ........................C=1, gamma=auto, kernel=rbf; total time=   0.2s\n",
      "[CV] END ........................C=1, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "[CV] END ...................C=10, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END ...................C=10, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ...................C=10, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ...................C=10, gamma=scale, kernel=linear; total time=   0.1s\n",
      "[CV] END ...................C=10, gamma=scale, kernel=linear; total time=   0.2s\n",
      "[CV] END ......................C=10, gamma=scale, kernel=rbf; total time=   0.3s\n",
      "[CV] END ......................C=10, gamma=scale, kernel=rbf; total time=   0.3s\n",
      "[CV] END ......................C=10, gamma=scale, kernel=rbf; total time=   0.3s\n",
      "[CV] END ......................C=10, gamma=scale, kernel=rbf; total time=   0.3s\n",
      "[CV] END ....................C=10, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ....................C=10, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ....................C=10, gamma=auto, kernel=linear; total time=   0.2s\n",
      "[CV] END ....................C=10, gamma=auto, kernel=linear; total time=   0.3s\n",
      "[CV] END ....................C=10, gamma=auto, kernel=linear; total time=   0.1s\n",
      "[CV] END ......................C=10, gamma=scale, kernel=rbf; total time=   0.4s\n",
      "[CV] END .......................C=10, gamma=auto, kernel=rbf; total time=   0.2s\n",
      "[CV] END .......................C=10, gamma=auto, kernel=rbf; total time=   0.2s\n",
      "[CV] END .......................C=10, gamma=auto, kernel=rbf; total time=   0.3s\n",
      "[CV] END .......................C=10, gamma=auto, kernel=rbf; total time=   0.2s\n",
      "[CV] END .......................C=10, gamma=auto, kernel=rbf; total time=   0.1s\n",
      "Mejor configuración encontrada:\n",
      "{'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Mejor F1-macro: 0.5817\n",
      "\n",
      "Resultados detallados por configuración:\n",
      "{'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'} -> F1-macro: 0.4170 (+/-0.0004)\n",
      "{'C': 0.1, 'gamma': 'scale', 'kernel': 'rbf'} -> F1-macro: 0.4170 (+/-0.0004)\n",
      "{'C': 0.1, 'gamma': 'auto', 'kernel': 'linear'} -> F1-macro: 0.4170 (+/-0.0004)\n",
      "{'C': 0.1, 'gamma': 'auto', 'kernel': 'rbf'} -> F1-macro: 0.4170 (+/-0.0004)\n",
      "{'C': 1, 'gamma': 'scale', 'kernel': 'linear'} -> F1-macro: 0.4170 (+/-0.0004)\n",
      "{'C': 1, 'gamma': 'scale', 'kernel': 'rbf'} -> F1-macro: 0.5009 (+/-0.0339)\n",
      "{'C': 1, 'gamma': 'auto', 'kernel': 'linear'} -> F1-macro: 0.4170 (+/-0.0004)\n",
      "{'C': 1, 'gamma': 'auto', 'kernel': 'rbf'} -> F1-macro: 0.4170 (+/-0.0004)\n",
      "{'C': 10, 'gamma': 'scale', 'kernel': 'linear'} -> F1-macro: 0.4988 (+/-0.0175)\n",
      "{'C': 10, 'gamma': 'scale', 'kernel': 'rbf'} -> F1-macro: 0.5817 (+/-0.0180)\n",
      "{'C': 10, 'gamma': 'auto', 'kernel': 'linear'} -> F1-macro: 0.4988 (+/-0.0175)\n",
      "{'C': 10, 'gamma': 'auto', 'kernel': 'rbf'} -> F1-macro: 0.4170 (+/-0.0004)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, f1_score, make_scorer\n",
    "\n",
    "# Definir el modelo y los hiperparámetros a probar\n",
    "svc = SVC(random_state=0)\n",
    "param_grid = {\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Configurar validación cruzada y búsqueda de hiperparámetros\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "grid_search = GridSearchCV(\n",
    "    svc,\n",
    "    param_grid,\n",
    "    scoring=make_scorer(f1_score, average='macro'),\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Ejecutar búsqueda\n",
    "grid_search.fit(X_train_reduced, train_df['Tag Value'])\n",
    "\n",
    "# Imprimir mejores resultados\n",
    "print(\"Mejor configuración encontrada:\")\n",
    "print(grid_search.best_params_)\n",
    "print(f\"Mejor F1-macro: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "print(\"\\nResultados detallados por configuración:\")\n",
    "means = grid_search.cv_results_['mean_test_score']\n",
    "stds = grid_search.cv_results_['std_test_score']\n",
    "params = grid_search.cv_results_['params']\n",
    "for mean, std, param in zip(means, stds, params):\n",
    "    print(f\"{param} -> F1-macro: {mean:.4f} (+/-{std:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98aa1724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machines (SVC):\n",
      "F1-macro scores por fold: [0.57233095 0.55762663 0.62539683 0.58510121 0.56152222]\n",
      "F1-macro promedio: 0.5804\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Definir el modelo de SVC\n",
    "svc_model = SVC(C=10,gamma='scale',kernel='rbf', random_state=0)\n",
    "\n",
    "# Evaluar el modelo con validación cruzada usando las representaciones reducidas (X_train_reduced)\n",
    "svc_scores = cross_val_score(svc_model, X_train_reduced, train_df['Tag Value'], cv=5, scoring='f1_macro')\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"Support Vector Machines (SVC):\")\n",
    "print(f\"F1-macro scores por fold: {svc_scores}\")\n",
    "print(f\"F1-macro promedio: {svc_scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15aa1190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7299    0.8700    0.7938       500\n",
      "           1     0.3750    0.1950    0.2566       200\n",
      "\n",
      "    accuracy                         0.6771       700\n",
      "   macro avg     0.5524    0.5325    0.5252       700\n",
      "weighted avg     0.6285    0.6771    0.6403       700\n",
      "\n",
      "Matriz de confusión:\n",
      "[[435  65]\n",
      " [161  39]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Entrenar el modelo en todo el conjunto de entrenamiento\n",
    "svc_model.fit(X_train_reduced, train_df['Tag Value'])\n",
    "\n",
    "# Predecir sobre el conjunto de validación/desarrollo\n",
    "y_pred = svc_model.predict(X_dev_reduced)\n",
    "y_true = dev_df['Tag Value']\n",
    "\n",
    "# Imprimir el reporte de clasificación\n",
    "print(\"Reporte de clasificación:\")\n",
    "print(classification_report(y_true, y_pred, digits=4))\n",
    "\n",
    "# Imprimir la matriz de confusión\n",
    "print(\"Matriz de confusión:\")\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f76969",
   "metadata": {},
   "source": [
    "## Multi-layer Perceptron (MLPClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d82a627a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(50,), solver=adam; total time=  10.6s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(50,), solver=adam; total time=  12.0s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(50,), solver=adam; total time=  13.6s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(50,), solver=adam; total time=  13.6s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(50,), solver=lbfgs; total time=   6.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.0001, hidden_layer_sizes=(50,), solver=lbfgs; total time=   9.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.0001, hidden_layer_sizes=(50,), solver=lbfgs; total time=  11.1s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(50,), solver=adam; total time=  16.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.0001, hidden_layer_sizes=(50,), solver=lbfgs; total time=  11.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.0001, hidden_layer_sizes=(50,), solver=lbfgs; total time=  10.7s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(100,), solver=adam; total time=  16.2s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(100,), solver=adam; total time=  16.1s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(100,), solver=adam; total time=  16.5s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(100,), solver=adam; total time=  17.0s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(100,), solver=lbfgs; total time=  10.3s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(100,), solver=lbfgs; total time=   9.0s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(100,), solver=adam; total time=  18.1s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(100,), solver=lbfgs; total time=  14.4s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(100, 50), solver=adam; total time=   7.3s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(100,), solver=lbfgs; total time=  14.3s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(100,), solver=lbfgs; total time=  11.9s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(100, 50), solver=adam; total time=   7.0s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(100, 50), solver=adam; total time=   7.9s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(100, 50), solver=adam; total time=   7.6s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(100, 50), solver=adam; total time=   7.4s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(100, 50), solver=lbfgs; total time=  38.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.0001, hidden_layer_sizes=(100, 50), solver=lbfgs; total time=  40.9s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(100, 50), solver=lbfgs; total time=  38.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.0001, hidden_layer_sizes=(100, 50), solver=lbfgs; total time=  42.2s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(150,), solver=adam; total time=  20.8s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(150,), solver=adam; total time=  22.7s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(150,), solver=adam; total time=  24.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.0001, hidden_layer_sizes=(100, 50), solver=lbfgs; total time=  36.4s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(150,), solver=adam; total time=  23.7s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(150,), solver=lbfgs; total time=  23.1s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(150,), solver=lbfgs; total time=  18.3s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(150,), solver=adam; total time=  26.8s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(150,), solver=lbfgs; total time=  15.6s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(150,), solver=lbfgs; total time=  17.4s\n",
      "[CV] END .alpha=0.001, hidden_layer_sizes=(50,), solver=adam; total time=  17.4s\n",
      "[CV] END alpha=0.0001, hidden_layer_sizes=(150,), solver=lbfgs; total time=  25.0s\n",
      "[CV] END .alpha=0.001, hidden_layer_sizes=(50,), solver=adam; total time=  13.3s\n",
      "[CV] END .alpha=0.001, hidden_layer_sizes=(50,), solver=adam; total time=  13.6s\n",
      "[CV] END .alpha=0.001, hidden_layer_sizes=(50,), solver=adam; total time=  13.8s\n",
      "[CV] END .alpha=0.001, hidden_layer_sizes=(50,), solver=adam; total time=  13.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, hidden_layer_sizes=(50,), solver=lbfgs; total time=  10.3s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(50,), solver=lbfgs; total time=   5.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, hidden_layer_sizes=(50,), solver=lbfgs; total time=  11.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, hidden_layer_sizes=(50,), solver=lbfgs; total time=  11.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, hidden_layer_sizes=(50,), solver=lbfgs; total time=  11.4s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(100,), solver=adam; total time=  17.6s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(100,), solver=adam; total time=  17.3s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(100,), solver=adam; total time=  16.6s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(100,), solver=adam; total time=  19.8s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(100,), solver=adam; total time=  18.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, hidden_layer_sizes=(100,), solver=lbfgs; total time=  23.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, hidden_layer_sizes=(100,), solver=lbfgs; total time=  22.0s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(100, 50), solver=adam; total time=   8.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, hidden_layer_sizes=(100,), solver=lbfgs; total time=  22.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, hidden_layer_sizes=(100,), solver=lbfgs; total time=  23.0s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(100, 50), solver=adam; total time=   8.8s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(100, 50), solver=adam; total time=   8.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, hidden_layer_sizes=(100,), solver=lbfgs; total time=  23.2s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(100, 50), solver=adam; total time=   7.9s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(100, 50), solver=adam; total time=   7.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, hidden_layer_sizes=(100, 50), solver=lbfgs; total time=  40.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, hidden_layer_sizes=(100, 50), solver=lbfgs; total time=  38.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, hidden_layer_sizes=(100, 50), solver=lbfgs; total time=  41.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, hidden_layer_sizes=(100, 50), solver=lbfgs; total time=  40.9s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(150,), solver=adam; total time=  21.3s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(150,), solver=adam; total time=  22.1s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(150,), solver=adam; total time=  21.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, hidden_layer_sizes=(100, 50), solver=lbfgs; total time=  37.6s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(150,), solver=adam; total time=  23.0s\n",
      "[CV] END alpha=0.001, hidden_layer_sizes=(150,), solver=adam; total time=  25.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, hidden_layer_sizes=(150,), solver=lbfgs; total time=  40.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, hidden_layer_sizes=(150,), solver=lbfgs; total time=  40.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, hidden_layer_sizes=(150,), solver=lbfgs; total time=  42.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, hidden_layer_sizes=(150,), solver=lbfgs; total time=  44.0s\n",
      "[CV] END ..alpha=0.01, hidden_layer_sizes=(50,), solver=adam; total time=  19.4s\n",
      "[CV] END ..alpha=0.01, hidden_layer_sizes=(50,), solver=adam; total time=  15.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, hidden_layer_sizes=(150,), solver=lbfgs; total time=  41.9s\n",
      "[CV] END ..alpha=0.01, hidden_layer_sizes=(50,), solver=adam; total time=  17.6s\n",
      "[CV] END ..alpha=0.01, hidden_layer_sizes=(50,), solver=adam; total time=  17.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .alpha=0.01, hidden_layer_sizes=(50,), solver=lbfgs; total time=  11.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .alpha=0.01, hidden_layer_sizes=(50,), solver=lbfgs; total time=  12.6s\n",
      "[CV] END ..alpha=0.01, hidden_layer_sizes=(50,), solver=adam; total time=  14.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .alpha=0.01, hidden_layer_sizes=(50,), solver=lbfgs; total time=  12.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .alpha=0.01, hidden_layer_sizes=(50,), solver=lbfgs; total time=  11.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .alpha=0.01, hidden_layer_sizes=(50,), solver=lbfgs; total time=  11.3s\n",
      "[CV] END .alpha=0.01, hidden_layer_sizes=(100,), solver=adam; total time=  15.2s\n",
      "[CV] END .alpha=0.01, hidden_layer_sizes=(100,), solver=adam; total time=  16.5s\n",
      "[CV] END .alpha=0.01, hidden_layer_sizes=(100,), solver=adam; total time=  16.3s\n",
      "[CV] END .alpha=0.01, hidden_layer_sizes=(100,), solver=adam; total time=  18.2s\n",
      "[CV] END .alpha=0.01, hidden_layer_sizes=(100,), solver=adam; total time=  17.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, hidden_layer_sizes=(100,), solver=lbfgs; total time=  20.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, hidden_layer_sizes=(100,), solver=lbfgs; total time=  24.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, hidden_layer_sizes=(100,), solver=lbfgs; total time=  25.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, hidden_layer_sizes=(100,), solver=lbfgs; total time=  25.5s\n",
      "[CV] END alpha=0.01, hidden_layer_sizes=(100, 50), solver=adam; total time=  10.8s\n",
      "[CV] END alpha=0.01, hidden_layer_sizes=(100, 50), solver=adam; total time=   9.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, hidden_layer_sizes=(100,), solver=lbfgs; total time=  25.2s\n",
      "[CV] END alpha=0.01, hidden_layer_sizes=(100, 50), solver=adam; total time=  10.9s\n",
      "[CV] END alpha=0.01, hidden_layer_sizes=(100, 50), solver=adam; total time=   7.8s\n",
      "[CV] END alpha=0.01, hidden_layer_sizes=(100, 50), solver=adam; total time=  10.9s\n",
      "[CV] END alpha=0.01, hidden_layer_sizes=(100, 50), solver=lbfgs; total time=  35.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, hidden_layer_sizes=(100, 50), solver=lbfgs; total time=  41.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, hidden_layer_sizes=(100, 50), solver=lbfgs; total time=  40.8s\n",
      "[CV] END alpha=0.01, hidden_layer_sizes=(100, 50), solver=lbfgs; total time=  41.5s\n",
      "[CV] END .alpha=0.01, hidden_layer_sizes=(150,), solver=adam; total time=  22.4s\n",
      "[CV] END .alpha=0.01, hidden_layer_sizes=(150,), solver=adam; total time=  19.8s\n",
      "[CV] END .alpha=0.01, hidden_layer_sizes=(150,), solver=adam; total time=  21.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, hidden_layer_sizes=(100, 50), solver=lbfgs; total time=  38.9s\n",
      "[CV] END .alpha=0.01, hidden_layer_sizes=(150,), solver=adam; total time=  20.6s\n",
      "[CV] END .alpha=0.01, hidden_layer_sizes=(150,), solver=adam; total time=  21.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, hidden_layer_sizes=(150,), solver=lbfgs; total time=  38.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, hidden_layer_sizes=(150,), solver=lbfgs; total time=  39.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, hidden_layer_sizes=(150,), solver=lbfgs; total time=  39.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, hidden_layer_sizes=(150,), solver=lbfgs; total time=  38.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/Documentos/ESCOM/NLP/ClickbaitDetection/venv/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.01, hidden_layer_sizes=(150,), solver=lbfgs; total time=  27.0s\n",
      "Mejor configuración encontrada:\n",
      "{'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'solver': 'adam'}\n",
      "Mejor F1-macro: 0.5903\n",
      "\n",
      "Resultados detallados por configuración:\n",
      "{'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'solver': 'adam'} -> F1-macro: 0.5903 (+/-0.0169)\n",
      "{'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'solver': 'lbfgs'} -> F1-macro: 0.5680 (+/-0.0130)\n",
      "{'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'solver': 'adam'} -> F1-macro: 0.5666 (+/-0.0331)\n",
      "{'alpha': 0.0001, 'hidden_layer_sizes': (100,), 'solver': 'lbfgs'} -> F1-macro: 0.5543 (+/-0.0246)\n",
      "{'alpha': 0.0001, 'hidden_layer_sizes': (100, 50), 'solver': 'adam'} -> F1-macro: 0.5710 (+/-0.0186)\n",
      "{'alpha': 0.0001, 'hidden_layer_sizes': (100, 50), 'solver': 'lbfgs'} -> F1-macro: 0.5667 (+/-0.0175)\n",
      "{'alpha': 0.0001, 'hidden_layer_sizes': (150,), 'solver': 'adam'} -> F1-macro: 0.5796 (+/-0.0194)\n",
      "{'alpha': 0.0001, 'hidden_layer_sizes': (150,), 'solver': 'lbfgs'} -> F1-macro: 0.5684 (+/-0.0268)\n",
      "{'alpha': 0.001, 'hidden_layer_sizes': (50,), 'solver': 'adam'} -> F1-macro: 0.5712 (+/-0.0173)\n",
      "{'alpha': 0.001, 'hidden_layer_sizes': (50,), 'solver': 'lbfgs'} -> F1-macro: 0.5651 (+/-0.0276)\n",
      "{'alpha': 0.001, 'hidden_layer_sizes': (100,), 'solver': 'adam'} -> F1-macro: 0.5619 (+/-0.0262)\n",
      "{'alpha': 0.001, 'hidden_layer_sizes': (100,), 'solver': 'lbfgs'} -> F1-macro: 0.5778 (+/-0.0202)\n",
      "{'alpha': 0.001, 'hidden_layer_sizes': (100, 50), 'solver': 'adam'} -> F1-macro: 0.5729 (+/-0.0163)\n",
      "{'alpha': 0.001, 'hidden_layer_sizes': (100, 50), 'solver': 'lbfgs'} -> F1-macro: 0.5756 (+/-0.0193)\n",
      "{'alpha': 0.001, 'hidden_layer_sizes': (150,), 'solver': 'adam'} -> F1-macro: 0.5761 (+/-0.0314)\n",
      "{'alpha': 0.001, 'hidden_layer_sizes': (150,), 'solver': 'lbfgs'} -> F1-macro: 0.5594 (+/-0.0159)\n",
      "{'alpha': 0.01, 'hidden_layer_sizes': (50,), 'solver': 'adam'} -> F1-macro: 0.5750 (+/-0.0292)\n",
      "{'alpha': 0.01, 'hidden_layer_sizes': (50,), 'solver': 'lbfgs'} -> F1-macro: 0.5672 (+/-0.0238)\n",
      "{'alpha': 0.01, 'hidden_layer_sizes': (100,), 'solver': 'adam'} -> F1-macro: 0.5744 (+/-0.0177)\n",
      "{'alpha': 0.01, 'hidden_layer_sizes': (100,), 'solver': 'lbfgs'} -> F1-macro: 0.5587 (+/-0.0152)\n",
      "{'alpha': 0.01, 'hidden_layer_sizes': (100, 50), 'solver': 'adam'} -> F1-macro: 0.5723 (+/-0.0075)\n",
      "{'alpha': 0.01, 'hidden_layer_sizes': (100, 50), 'solver': 'lbfgs'} -> F1-macro: 0.5740 (+/-0.0330)\n",
      "{'alpha': 0.01, 'hidden_layer_sizes': (150,), 'solver': 'adam'} -> F1-macro: 0.5874 (+/-0.0159)\n",
      "{'alpha': 0.01, 'hidden_layer_sizes': (150,), 'solver': 'lbfgs'} -> F1-macro: 0.5781 (+/-0.0186)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "# Definir el modelo y los hiperparámetros a probar\n",
    "mlp = MLPClassifier(random_state=0, max_iter=2000)\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (100, 50), (150,)],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'solver': ['adam', 'lbfgs'],\n",
    "}\n",
    "\n",
    "# Configurar validación cruzada y búsqueda de hiperparámetros\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "grid_search = GridSearchCV(\n",
    "    mlp,\n",
    "    param_grid,\n",
    "    scoring=make_scorer(f1_score, average='macro'),\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Ejecutar búsqueda\n",
    "grid_search.fit(X_train_reduced, train_df['Tag Value'])\n",
    "\n",
    "# Imprimir mejores resultados\n",
    "print(\"Mejor configuración encontrada:\")\n",
    "print(grid_search.best_params_)\n",
    "print(f\"Mejor F1-macro: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "print(\"\\nResultados detallados por configuración:\")\n",
    "means = grid_search.cv_results_['mean_test_score']\n",
    "stds = grid_search.cv_results_['std_test_score']\n",
    "params = grid_search.cv_results_['params']\n",
    "for mean, std, param in zip(means, stds, params):\n",
    "    print(f\"{param} -> F1-macro: {mean:.4f} (+/-{std:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d3609e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-layer Perceptron (MLPClassifier):\n",
      "F1-macro scores por fold: [0.58867521 0.59923368 0.60903783 0.58680681 0.58314428]\n",
      "F1-macro promedio: 0.5934\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Definir el modelo de MLP\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(50,), max_iter=2000, alpha=0.0010, solver='adam', random_state=0)\n",
    "\n",
    "# Evaluar el modelo con validación cruzada usando las representaciones reducidas (X_train_reduced)\n",
    "mlp_scores = cross_val_score(mlp_model, X_train_reduced, train_df['Tag Value'], cv=5, scoring='f1_macro')\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"Multi-layer Perceptron (MLPClassifier):\")\n",
    "print(f\"F1-macro scores por fold: {mlp_scores}\")\n",
    "print(f\"F1-macro promedio: {mlp_scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04657299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7258    0.8680    0.7905       500\n",
      "           1     0.3529    0.1800    0.2384       200\n",
      "\n",
      "    accuracy                         0.6714       700\n",
      "   macro avg     0.5393    0.5240    0.5145       700\n",
      "weighted avg     0.6192    0.6714    0.6328       700\n",
      "\n",
      "Matriz de confusión:\n",
      "[[434  66]\n",
      " [164  36]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Entrenar el modelo en todo el conjunto de entrenamiento\n",
    "mlp_model.fit(X_train_reduced, train_df['Tag Value'])\n",
    "\n",
    "# Predecir sobre el conjunto de validación/desarrollo\n",
    "y_pred = mlp_model.predict(X_dev_reduced)\n",
    "y_true = dev_df['Tag Value']\n",
    "\n",
    "# Imprimir el reporte de clasificación\n",
    "print(\"Reporte de clasificación:\")\n",
    "print(classification_report(y_true, y_pred, digits=4))\n",
    "\n",
    "# Imprimir la matriz de confusión\n",
    "print(\"Matriz de confusión:\")\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09802203",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68122211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.4s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   4.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   4.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   1.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   0.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   3.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   1.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.9s\n",
      "Mejor configuración encontrada:\n",
      "{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Mejor F1-macro: 0.5198\n",
      "\n",
      "Resultados detallados por configuración:\n",
      "{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50} -> F1-macro: 0.5011 (+/-0.0245)\n",
      "{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100} -> F1-macro: 0.4901 (+/-0.0153)\n",
      "{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200} -> F1-macro: 0.4910 (+/-0.0192)\n",
      "{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50} -> F1-macro: 0.5198 (+/-0.0161)\n",
      "{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100} -> F1-macro: 0.4861 (+/-0.0214)\n",
      "{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200} -> F1-macro: 0.4876 (+/-0.0318)\n",
      "{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50} -> F1-macro: 0.5107 (+/-0.0237)\n",
      "{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100} -> F1-macro: 0.4966 (+/-0.0171)\n",
      "{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200} -> F1-macro: 0.4996 (+/-0.0231)\n",
      "{'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 50} -> F1-macro: 0.5124 (+/-0.0185)\n",
      "{'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100} -> F1-macro: 0.4920 (+/-0.0239)\n",
      "{'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200} -> F1-macro: 0.4923 (+/-0.0204)\n",
      "{'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50} -> F1-macro: 0.5118 (+/-0.0194)\n",
      "{'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100} -> F1-macro: 0.4940 (+/-0.0188)\n",
      "{'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200} -> F1-macro: 0.4907 (+/-0.0239)\n",
      "{'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 50} -> F1-macro: 0.4981 (+/-0.0204)\n",
      "{'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 100} -> F1-macro: 0.4853 (+/-0.0230)\n",
      "{'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200} -> F1-macro: 0.4817 (+/-0.0172)\n",
      "{'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 50} -> F1-macro: 0.4920 (+/-0.0289)\n",
      "{'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100} -> F1-macro: 0.4723 (+/-0.0297)\n",
      "{'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200} -> F1-macro: 0.4747 (+/-0.0304)\n",
      "{'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 50} -> F1-macro: 0.4920 (+/-0.0289)\n",
      "{'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 100} -> F1-macro: 0.4723 (+/-0.0297)\n",
      "{'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 200} -> F1-macro: 0.4747 (+/-0.0304)\n",
      "{'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 50} -> F1-macro: 0.4918 (+/-0.0282)\n",
      "{'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100} -> F1-macro: 0.4732 (+/-0.0260)\n",
      "{'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 200} -> F1-macro: 0.4738 (+/-0.0201)\n",
      "{'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50} -> F1-macro: 0.4813 (+/-0.0335)\n",
      "{'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100} -> F1-macro: 0.4748 (+/-0.0244)\n",
      "{'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200} -> F1-macro: 0.4629 (+/-0.0225)\n",
      "{'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50} -> F1-macro: 0.4815 (+/-0.0251)\n",
      "{'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100} -> F1-macro: 0.4772 (+/-0.0212)\n",
      "{'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200} -> F1-macro: 0.4744 (+/-0.0235)\n",
      "{'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50} -> F1-macro: 0.4671 (+/-0.0247)\n",
      "{'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100} -> F1-macro: 0.4598 (+/-0.0213)\n",
      "{'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200} -> F1-macro: 0.4682 (+/-0.0248)\n",
      "{'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 50} -> F1-macro: 0.4860 (+/-0.0277)\n",
      "{'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100} -> F1-macro: 0.4736 (+/-0.0289)\n",
      "{'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200} -> F1-macro: 0.4683 (+/-0.0257)\n",
      "{'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50} -> F1-macro: 0.4772 (+/-0.0208)\n",
      "{'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100} -> F1-macro: 0.4660 (+/-0.0236)\n",
      "{'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200} -> F1-macro: 0.4674 (+/-0.0243)\n",
      "{'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 50} -> F1-macro: 0.4776 (+/-0.0231)\n",
      "{'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 100} -> F1-macro: 0.4760 (+/-0.0213)\n",
      "{'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200} -> F1-macro: 0.4661 (+/-0.0197)\n",
      "{'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 50} -> F1-macro: 0.4768 (+/-0.0224)\n",
      "{'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100} -> F1-macro: 0.4661 (+/-0.0217)\n",
      "{'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200} -> F1-macro: 0.4606 (+/-0.0252)\n",
      "{'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 50} -> F1-macro: 0.4768 (+/-0.0224)\n",
      "{'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 100} -> F1-macro: 0.4661 (+/-0.0217)\n",
      "{'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 200} -> F1-macro: 0.4606 (+/-0.0252)\n",
      "{'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 50} -> F1-macro: 0.4734 (+/-0.0243)\n",
      "{'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100} -> F1-macro: 0.4623 (+/-0.0265)\n",
      "{'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 200} -> F1-macro: 0.4621 (+/-0.0240)\n",
      "{'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50} -> F1-macro: 0.5035 (+/-0.0209)\n",
      "{'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100} -> F1-macro: 0.4979 (+/-0.0160)\n",
      "{'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200} -> F1-macro: 0.4960 (+/-0.0130)\n",
      "{'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50} -> F1-macro: 0.5083 (+/-0.0097)\n",
      "{'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100} -> F1-macro: 0.4887 (+/-0.0255)\n",
      "{'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200} -> F1-macro: 0.4971 (+/-0.0220)\n",
      "{'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50} -> F1-macro: 0.5048 (+/-0.0213)\n",
      "{'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100} -> F1-macro: 0.5003 (+/-0.0178)\n",
      "{'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200} -> F1-macro: 0.4989 (+/-0.0196)\n",
      "{'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 50} -> F1-macro: 0.5148 (+/-0.0171)\n",
      "{'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100} -> F1-macro: 0.4918 (+/-0.0212)\n",
      "{'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200} -> F1-macro: 0.4894 (+/-0.0259)\n",
      "{'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50} -> F1-macro: 0.5044 (+/-0.0274)\n",
      "{'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100} -> F1-macro: 0.4984 (+/-0.0190)\n",
      "{'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200} -> F1-macro: 0.4874 (+/-0.0263)\n",
      "{'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 50} -> F1-macro: 0.5026 (+/-0.0166)\n",
      "{'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 100} -> F1-macro: 0.4865 (+/-0.0250)\n",
      "{'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200} -> F1-macro: 0.4828 (+/-0.0191)\n",
      "{'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 50} -> F1-macro: 0.4922 (+/-0.0267)\n",
      "{'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100} -> F1-macro: 0.4755 (+/-0.0314)\n",
      "{'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200} -> F1-macro: 0.4747 (+/-0.0304)\n",
      "{'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 50} -> F1-macro: 0.4922 (+/-0.0267)\n",
      "{'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 100} -> F1-macro: 0.4755 (+/-0.0314)\n",
      "{'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 200} -> F1-macro: 0.4747 (+/-0.0304)\n",
      "{'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 50} -> F1-macro: 0.4931 (+/-0.0253)\n",
      "{'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100} -> F1-macro: 0.4702 (+/-0.0267)\n",
      "{'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 200} -> F1-macro: 0.4740 (+/-0.0196)\n",
      "{'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50} -> F1-macro: 0.5011 (+/-0.0245)\n",
      "{'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100} -> F1-macro: 0.4914 (+/-0.0171)\n",
      "{'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200} -> F1-macro: 0.4910 (+/-0.0192)\n",
      "{'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50} -> F1-macro: 0.5198 (+/-0.0161)\n",
      "{'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100} -> F1-macro: 0.4861 (+/-0.0214)\n",
      "{'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200} -> F1-macro: 0.4876 (+/-0.0318)\n",
      "{'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50} -> F1-macro: 0.5107 (+/-0.0237)\n",
      "{'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100} -> F1-macro: 0.4947 (+/-0.0157)\n",
      "{'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200} -> F1-macro: 0.4980 (+/-0.0254)\n",
      "{'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 50} -> F1-macro: 0.5124 (+/-0.0185)\n",
      "{'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100} -> F1-macro: 0.4920 (+/-0.0239)\n",
      "{'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200} -> F1-macro: 0.4923 (+/-0.0204)\n",
      "{'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50} -> F1-macro: 0.5118 (+/-0.0194)\n",
      "{'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100} -> F1-macro: 0.4940 (+/-0.0188)\n",
      "{'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200} -> F1-macro: 0.4907 (+/-0.0239)\n",
      "{'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 50} -> F1-macro: 0.4981 (+/-0.0204)\n",
      "{'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 100} -> F1-macro: 0.4853 (+/-0.0230)\n",
      "{'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200} -> F1-macro: 0.4817 (+/-0.0172)\n",
      "{'max_depth': 30, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 50} -> F1-macro: 0.4920 (+/-0.0289)\n",
      "{'max_depth': 30, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100} -> F1-macro: 0.4723 (+/-0.0297)\n",
      "{'max_depth': 30, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200} -> F1-macro: 0.4747 (+/-0.0304)\n",
      "{'max_depth': 30, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 50} -> F1-macro: 0.4920 (+/-0.0289)\n",
      "{'max_depth': 30, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 100} -> F1-macro: 0.4723 (+/-0.0297)\n",
      "{'max_depth': 30, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 200} -> F1-macro: 0.4747 (+/-0.0304)\n",
      "{'max_depth': 30, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 50} -> F1-macro: 0.4918 (+/-0.0282)\n",
      "{'max_depth': 30, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100} -> F1-macro: 0.4732 (+/-0.0260)\n",
      "{'max_depth': 30, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 200} -> F1-macro: 0.4738 (+/-0.0201)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "# Definir el modelo y los hiperparámetros a probar\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Configurar validación cruzada y búsqueda de hiperparámetros\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "grid_search = GridSearchCV(\n",
    "    rf,\n",
    "    param_grid,\n",
    "    scoring=make_scorer(f1_score, average='macro'),\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Ejecutar búsqueda\n",
    "grid_search.fit(X_train_reduced, train_df['Tag Value'])\n",
    "\n",
    "# Imprimir mejores resultados\n",
    "print(\"Mejor configuración encontrada:\")\n",
    "print(grid_search.best_params_)\n",
    "print(f\"Mejor F1-macro: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "print(\"\\nResultados detallados por configuración:\")\n",
    "means = grid_search.cv_results_['mean_test_score']\n",
    "stds = grid_search.cv_results_['std_test_score']\n",
    "params = grid_search.cv_results_['params']\n",
    "for mean, std, param in zip(means, stds, params):\n",
    "    print(f\"{param} -> F1-macro: {mean:.4f} (+/-{std:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20f54c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "F1-macro scores por fold: [0.50550766 0.49570826 0.51762523 0.48600529 0.51152933]\n",
      "F1-macro promedio: 0.5033\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Definir el modelo de Random Forest\n",
    "rf_model = RandomForestClassifier(max_depth=None, min_samples_leaf=1, min_samples_split=5,n_estimators=50, random_state=0)\n",
    "\n",
    "# Evaluar el modelo con validación cruzada usando las representaciones reducidas (X_train_reduced)\n",
    "rf_scores = cross_val_score(rf_model, X_train_reduced, train_df['Tag Value'], cv=5, scoring='f1_macro')\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"Random Forest:\")\n",
    "print(f\"F1-macro scores por fold: {rf_scores}\")\n",
    "print(f\"F1-macro promedio: {rf_scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "636070f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7259    0.9640    0.8282       500\n",
      "           1     0.5000    0.0900    0.1525       200\n",
      "\n",
      "    accuracy                         0.7143       700\n",
      "   macro avg     0.6130    0.5270    0.4904       700\n",
      "weighted avg     0.6614    0.7143    0.6351       700\n",
      "\n",
      "Matriz de confusión:\n",
      "[[482  18]\n",
      " [182  18]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Entrenar el modelo en todo el conjunto de entrenamiento\n",
    "rf_model.fit(X_train_reduced, train_df['Tag Value'])\n",
    "\n",
    "# Predecir sobre el conjunto de validación/desarrollo\n",
    "y_pred = rf_model.predict(X_dev_reduced)\n",
    "y_true = dev_df['Tag Value']\n",
    "\n",
    "# Imprimir el reporte de clasificación\n",
    "print(\"Reporte de clasificación:\")\n",
    "print(classification_report(y_true, y_pred, digits=4))\n",
    "\n",
    "# Imprimir la matriz de confusión\n",
    "print(\"Matriz de confusión:\")\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299696c7",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58ad7391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=50, subsample=0.8; total time=   2.0s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=50, subsample=0.8; total time=   2.0s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=50, subsample=0.8; total time=   2.1s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=50, subsample=0.8; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=50, subsample=0.8; total time=   1.8s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=50, subsample=1.0; total time=   2.3s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=50, subsample=1.0; total time=   2.3s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=50, subsample=1.0; total time=   2.3s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=50, subsample=1.0; total time=   2.4s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=50, subsample=1.0; total time=   2.2s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=100, subsample=0.8; total time=   3.7s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=100, subsample=0.8; total time=   3.7s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=100, subsample=0.8; total time=   3.8s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=100, subsample=0.8; total time=   3.7s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=100, subsample=0.8; total time=   3.8s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=100, subsample=1.0; total time=   4.7s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=100, subsample=1.0; total time=   4.7s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=100, subsample=1.0; total time=   4.7s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=100, subsample=1.0; total time=   4.8s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=100, subsample=1.0; total time=   4.8s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=200, subsample=0.8; total time=   7.7s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=200, subsample=0.8; total time=   7.8s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=200, subsample=0.8; total time=   7.9s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=200, subsample=0.8; total time=   7.8s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=200, subsample=0.8; total time=   7.8s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=200, subsample=1.0; total time=  10.0s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=200, subsample=1.0; total time=  10.3s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=200, subsample=1.0; total time=  10.0s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=50, subsample=0.8; total time=   3.0s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=50, subsample=0.8; total time=   3.0s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=200, subsample=1.0; total time=  10.2s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=50, subsample=0.8; total time=   3.0s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=50, subsample=0.8; total time=   2.8s\n",
      "[CV] END learning_rate=0.01, max_depth=2, n_estimators=200, subsample=1.0; total time=  10.0s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=50, subsample=0.8; total time=   2.9s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=50, subsample=1.0; total time=   3.8s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=50, subsample=1.0; total time=   3.7s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=50, subsample=1.0; total time=   3.6s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=50, subsample=1.0; total time=   3.7s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=50, subsample=1.0; total time=   3.8s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   6.0s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   5.9s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   5.8s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   5.9s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8; total time=   5.9s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   7.6s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   7.7s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   7.3s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   7.6s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=100, subsample=1.0; total time=   7.6s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=  12.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=  12.0s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=  12.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=  12.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=  12.0s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=  15.1s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=  15.2s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=  15.1s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=50, subsample=0.8; total time=   4.7s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=50, subsample=0.8; total time=   4.8s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=  15.2s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=50, subsample=0.8; total time=   4.7s\n",
      "[CV] END learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=  15.3s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=50, subsample=0.8; total time=   4.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=50, subsample=0.8; total time=   4.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=50, subsample=1.0; total time=   6.1s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=50, subsample=1.0; total time=   6.1s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=50, subsample=1.0; total time=   6.5s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=50, subsample=1.0; total time=   6.3s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=50, subsample=1.0; total time=   6.0s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   9.5s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   9.4s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=  10.0s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=  10.0s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.8; total time=   9.4s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=  12.2s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=  12.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=  12.3s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=  12.0s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0; total time=  12.5s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=  19.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=  19.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=  19.2s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=  19.9s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=  19.8s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=  25.1s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=  25.2s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=50, subsample=0.8; total time=   2.1s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=  24.9s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=50, subsample=0.8; total time=   2.1s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=50, subsample=0.8; total time=   2.1s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=50, subsample=0.8; total time=   2.1s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=50, subsample=0.8; total time=   2.2s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=50, subsample=1.0; total time=   2.6s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=50, subsample=1.0; total time=   2.7s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=50, subsample=1.0; total time=   2.7s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=  25.6s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=50, subsample=1.0; total time=   2.7s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=50, subsample=1.0; total time=   2.7s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=100, subsample=0.8; total time=   4.3s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=100, subsample=0.8; total time=   4.5s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=100, subsample=0.8; total time=   4.2s\n",
      "[CV] END learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=  25.0s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=100, subsample=0.8; total time=   4.4s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=100, subsample=0.8; total time=   4.4s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=100, subsample=1.0; total time=   5.3s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=100, subsample=1.0; total time=   5.3s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=100, subsample=1.0; total time=   5.3s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=100, subsample=1.0; total time=   5.5s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=100, subsample=1.0; total time=   5.4s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=200, subsample=0.8; total time=   8.7s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=200, subsample=0.8; total time=   8.6s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=200, subsample=0.8; total time=   8.6s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=200, subsample=0.8; total time=   8.5s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=200, subsample=0.8; total time=   8.6s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=200, subsample=1.0; total time=  10.5s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=200, subsample=1.0; total time=  10.9s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=200, subsample=1.0; total time=  10.7s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=50, subsample=0.8; total time=   3.0s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=50, subsample=0.8; total time=   3.1s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=200, subsample=1.0; total time=  10.8s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=50, subsample=0.8; total time=   3.0s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=50, subsample=0.8; total time=   3.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=50, subsample=0.8; total time=   3.1s\n",
      "[CV] END learning_rate=0.05, max_depth=2, n_estimators=200, subsample=1.0; total time=  10.6s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=50, subsample=1.0; total time=   3.9s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=50, subsample=1.0; total time=   3.9s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=50, subsample=1.0; total time=   3.8s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=50, subsample=1.0; total time=   4.0s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=50, subsample=1.0; total time=   3.8s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=100, subsample=0.8; total time=   6.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=100, subsample=0.8; total time=   6.3s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=100, subsample=0.8; total time=   6.5s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=100, subsample=0.8; total time=   6.2s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=100, subsample=0.8; total time=   6.2s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=100, subsample=1.0; total time=   7.8s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=100, subsample=1.0; total time=   8.0s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=100, subsample=1.0; total time=   7.8s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=100, subsample=1.0; total time=   7.8s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=100, subsample=1.0; total time=   7.9s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.8; total time=  12.5s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.8; total time=  13.3s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.8; total time=  13.0s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.8; total time=  13.8s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.8; total time=  13.7s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=200, subsample=1.0; total time=  16.6s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=200, subsample=1.0; total time=  17.0s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=200, subsample=1.0; total time=  16.6s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=50, subsample=0.8; total time=   5.1s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=200, subsample=1.0; total time=  15.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=50, subsample=0.8; total time=   5.0s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=50, subsample=0.8; total time=   4.8s\n",
      "[CV] END learning_rate=0.05, max_depth=3, n_estimators=200, subsample=1.0; total time=  16.0s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=50, subsample=0.8; total time=   5.1s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=50, subsample=0.8; total time=   5.1s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=50, subsample=1.0; total time=   6.3s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=50, subsample=1.0; total time=   6.7s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=50, subsample=1.0; total time=   6.6s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=50, subsample=1.0; total time=   6.1s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=50, subsample=1.0; total time=   6.3s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.8; total time=  10.3s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.8; total time=  10.1s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.8; total time=  10.3s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.8; total time=   9.7s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.8; total time=  10.0s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=100, subsample=1.0; total time=  12.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=100, subsample=1.0; total time=  12.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=100, subsample=1.0; total time=  12.6s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=100, subsample=1.0; total time=  12.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=100, subsample=1.0; total time=  12.6s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.8; total time=  19.8s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.8; total time=  19.9s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.8; total time=  20.2s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.8; total time=  20.0s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.8; total time=  19.6s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=200, subsample=1.0; total time=  25.6s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=200, subsample=1.0; total time=  25.5s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=50, subsample=0.8; total time=   2.1s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=200, subsample=1.0; total time=  25.2s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=50, subsample=0.8; total time=   2.1s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=50, subsample=0.8; total time=   2.1s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=50, subsample=0.8; total time=   2.1s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=50, subsample=0.8; total time=   2.1s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=50, subsample=1.0; total time=   2.7s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=50, subsample=1.0; total time=   2.7s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=200, subsample=1.0; total time=  25.6s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=50, subsample=1.0; total time=   2.9s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=50, subsample=1.0; total time=   2.9s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=50, subsample=1.0; total time=   2.6s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=100, subsample=0.8; total time=   4.3s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=100, subsample=0.8; total time=   4.2s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=100, subsample=0.8; total time=   4.4s\n",
      "[CV] END learning_rate=0.05, max_depth=5, n_estimators=200, subsample=1.0; total time=  25.4s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=100, subsample=0.8; total time=   4.2s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=100, subsample=0.8; total time=   4.3s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=100, subsample=1.0; total time=   5.3s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=100, subsample=1.0; total time=   5.6s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=100, subsample=1.0; total time=   5.7s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=100, subsample=1.0; total time=   5.6s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=100, subsample=1.0; total time=   5.4s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=200, subsample=0.8; total time=   8.2s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=200, subsample=0.8; total time=   8.6s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=200, subsample=0.8; total time=   8.6s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=200, subsample=0.8; total time=   8.6s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=200, subsample=0.8; total time=   8.9s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=200, subsample=1.0; total time=  10.8s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=200, subsample=1.0; total time=  11.1s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=200, subsample=1.0; total time=  10.6s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=50, subsample=0.8; total time=   3.2s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=50, subsample=0.8; total time=   3.2s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=200, subsample=1.0; total time=  10.6s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=50, subsample=0.8; total time=   3.2s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=50, subsample=0.8; total time=   3.1s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=50, subsample=0.8; total time=   3.2s\n",
      "[CV] END learning_rate=0.1, max_depth=2, n_estimators=200, subsample=1.0; total time=  10.9s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=50, subsample=1.0; total time=   4.0s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=50, subsample=1.0; total time=   4.0s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=50, subsample=1.0; total time=   3.9s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=50, subsample=1.0; total time=   4.0s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=50, subsample=1.0; total time=   4.2s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   6.4s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   6.4s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   6.5s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   6.1s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8; total time=   6.2s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   8.1s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   7.9s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   8.0s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   7.9s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time=   8.1s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=  12.8s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=  12.7s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=  12.5s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=  12.5s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8; total time=  12.8s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=  16.0s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=  15.8s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=  16.1s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=50, subsample=0.8; total time=   5.5s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=50, subsample=0.8; total time=   5.0s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=  16.5s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=50, subsample=0.8; total time=   5.0s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=50, subsample=0.8; total time=   5.2s\n",
      "[CV] END learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0; total time=  16.7s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=50, subsample=0.8; total time=   5.3s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=50, subsample=1.0; total time=   6.3s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=50, subsample=1.0; total time=   6.5s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=50, subsample=1.0; total time=   6.3s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=50, subsample=1.0; total time=   6.4s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=50, subsample=1.0; total time=   6.4s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=  10.3s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=  10.1s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=  10.2s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=   9.9s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8; total time=  10.0s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=  13.1s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=  13.9s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=  13.3s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=  13.2s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0; total time=  13.6s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=  19.7s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=  20.9s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=  19.9s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=  20.2s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8; total time=  20.8s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=  26.1s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=  25.6s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=  25.6s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=  24.0s\n",
      "[CV] END learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0; total time=  22.7s\n",
      "Mejor configuración encontrada:\n",
      "{'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Mejor F1-macro: 0.5699\n",
      "\n",
      "Resultados detallados por configuración:\n",
      "{'learning_rate': 0.01, 'max_depth': 2, 'n_estimators': 50, 'subsample': 0.8} -> F1-macro: 0.4170 (+/-0.0004)\n",
      "{'learning_rate': 0.01, 'max_depth': 2, 'n_estimators': 50, 'subsample': 1.0} -> F1-macro: 0.4170 (+/-0.0004)\n",
      "{'learning_rate': 0.01, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.8} -> F1-macro: 0.4170 (+/-0.0004)\n",
      "{'learning_rate': 0.01, 'max_depth': 2, 'n_estimators': 100, 'subsample': 1.0} -> F1-macro: 0.4170 (+/-0.0004)\n",
      "{'learning_rate': 0.01, 'max_depth': 2, 'n_estimators': 200, 'subsample': 0.8} -> F1-macro: 0.4235 (+/-0.0061)\n",
      "{'learning_rate': 0.01, 'max_depth': 2, 'n_estimators': 200, 'subsample': 1.0} -> F1-macro: 0.4285 (+/-0.0097)\n",
      "{'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50, 'subsample': 0.8} -> F1-macro: 0.4170 (+/-0.0004)\n",
      "{'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50, 'subsample': 1.0} -> F1-macro: 0.4170 (+/-0.0004)\n",
      "{'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.8} -> F1-macro: 0.4167 (+/-0.0007)\n",
      "{'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100, 'subsample': 1.0} -> F1-macro: 0.4214 (+/-0.0072)\n",
      "{'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200, 'subsample': 0.8} -> F1-macro: 0.4410 (+/-0.0020)\n",
      "{'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200, 'subsample': 1.0} -> F1-macro: 0.4408 (+/-0.0064)\n",
      "{'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 50, 'subsample': 0.8} -> F1-macro: 0.4170 (+/-0.0004)\n",
      "{'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 50, 'subsample': 1.0} -> F1-macro: 0.4167 (+/-0.0005)\n",
      "{'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.8} -> F1-macro: 0.4386 (+/-0.0113)\n",
      "{'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 100, 'subsample': 1.0} -> F1-macro: 0.4400 (+/-0.0198)\n",
      "{'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 200, 'subsample': 0.8} -> F1-macro: 0.4808 (+/-0.0242)\n",
      "{'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 200, 'subsample': 1.0} -> F1-macro: 0.4717 (+/-0.0186)\n",
      "{'learning_rate': 0.05, 'max_depth': 2, 'n_estimators': 50, 'subsample': 0.8} -> F1-macro: 0.4294 (+/-0.0063)\n",
      "{'learning_rate': 0.05, 'max_depth': 2, 'n_estimators': 50, 'subsample': 1.0} -> F1-macro: 0.4351 (+/-0.0095)\n",
      "{'learning_rate': 0.05, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.8} -> F1-macro: 0.4627 (+/-0.0146)\n",
      "{'learning_rate': 0.05, 'max_depth': 2, 'n_estimators': 100, 'subsample': 1.0} -> F1-macro: 0.4572 (+/-0.0190)\n",
      "{'learning_rate': 0.05, 'max_depth': 2, 'n_estimators': 200, 'subsample': 0.8} -> F1-macro: 0.5132 (+/-0.0205)\n",
      "{'learning_rate': 0.05, 'max_depth': 2, 'n_estimators': 200, 'subsample': 1.0} -> F1-macro: 0.5054 (+/-0.0252)\n",
      "{'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 50, 'subsample': 0.8} -> F1-macro: 0.4607 (+/-0.0198)\n",
      "{'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 50, 'subsample': 1.0} -> F1-macro: 0.4549 (+/-0.0149)\n",
      "{'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.8} -> F1-macro: 0.5028 (+/-0.0344)\n",
      "{'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 100, 'subsample': 1.0} -> F1-macro: 0.4969 (+/-0.0297)\n",
      "{'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 200, 'subsample': 0.8} -> F1-macro: 0.5402 (+/-0.0231)\n",
      "{'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 200, 'subsample': 1.0} -> F1-macro: 0.5261 (+/-0.0247)\n",
      "{'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 50, 'subsample': 0.8} -> F1-macro: 0.4930 (+/-0.0277)\n",
      "{'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 50, 'subsample': 1.0} -> F1-macro: 0.4889 (+/-0.0259)\n",
      "{'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.8} -> F1-macro: 0.5313 (+/-0.0190)\n",
      "{'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 100, 'subsample': 1.0} -> F1-macro: 0.5263 (+/-0.0238)\n",
      "{'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 200, 'subsample': 0.8} -> F1-macro: 0.5502 (+/-0.0155)\n",
      "{'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 200, 'subsample': 1.0} -> F1-macro: 0.5370 (+/-0.0134)\n",
      "{'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 50, 'subsample': 0.8} -> F1-macro: 0.4683 (+/-0.0244)\n",
      "{'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 50, 'subsample': 1.0} -> F1-macro: 0.4710 (+/-0.0186)\n",
      "{'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.8} -> F1-macro: 0.5170 (+/-0.0299)\n",
      "{'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 100, 'subsample': 1.0} -> F1-macro: 0.4997 (+/-0.0202)\n",
      "{'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 200, 'subsample': 0.8} -> F1-macro: 0.5557 (+/-0.0209)\n",
      "{'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 200, 'subsample': 1.0} -> F1-macro: 0.5419 (+/-0.0190)\n",
      "{'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50, 'subsample': 0.8} -> F1-macro: 0.5117 (+/-0.0287)\n",
      "{'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50, 'subsample': 1.0} -> F1-macro: 0.5048 (+/-0.0338)\n",
      "{'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.8} -> F1-macro: 0.5588 (+/-0.0205)\n",
      "{'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 1.0} -> F1-macro: 0.5258 (+/-0.0302)\n",
      "{'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'subsample': 0.8} -> F1-macro: 0.5699 (+/-0.0145)\n",
      "{'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'subsample': 1.0} -> F1-macro: 0.5466 (+/-0.0254)\n",
      "{'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 50, 'subsample': 0.8} -> F1-macro: 0.5332 (+/-0.0196)\n",
      "{'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 50, 'subsample': 1.0} -> F1-macro: 0.5359 (+/-0.0229)\n",
      "{'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.8} -> F1-macro: 0.5507 (+/-0.0251)\n",
      "{'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100, 'subsample': 1.0} -> F1-macro: 0.5504 (+/-0.0164)\n",
      "{'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200, 'subsample': 0.8} -> F1-macro: 0.5561 (+/-0.0199)\n",
      "{'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200, 'subsample': 1.0} -> F1-macro: 0.5667 (+/-0.0179)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "# Definir el modelo y los hiperparámetros a probar\n",
    "gb = GradientBoostingClassifier(random_state=0)\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [2, 3, 5],\n",
    "    'subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Configurar validación cruzada y búsqueda de hiperparámetros\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "grid_search = GridSearchCV(\n",
    "    gb,\n",
    "    param_grid,\n",
    "    scoring=make_scorer(f1_score, average='macro'),\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Ejecutar búsqueda\n",
    "grid_search.fit(X_train_reduced, train_df['Tag Value'])\n",
    "\n",
    "# Imprimir mejores resultados\n",
    "print(\"Mejor configuración encontrada:\")\n",
    "print(grid_search.best_params_)\n",
    "print(f\"Mejor F1-macro: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "print(\"\\nResultados detallados por configuración:\")\n",
    "means = grid_search.cv_results_['mean_test_score']\n",
    "stds = grid_search.cv_results_['std_test_score']\n",
    "params = grid_search.cv_results_['params']\n",
    "for mean, std, param in zip(means, stds, params):\n",
    "    print(f\"{param} -> F1-macro: {mean:.4f} (+/-{std:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c416888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting:\n",
      "F1-macro scores por fold: [0.55576535 0.5437727  0.6040404  0.56991781 0.54546617]\n",
      "F1-macro promedio: 0.5638\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Definir el modelo de Gradient Boosting\n",
    "gb_model = GradientBoostingClassifier(subsample=0.8,n_estimators=200, learning_rate=0.1, max_depth=3, random_state=0)\n",
    "\n",
    "# Evaluar el modelo con validación cruzada usando las representaciones reducidas (X_train_reduced)\n",
    "gb_scores = cross_val_score(gb_model, X_train_reduced, train_df['Tag Value'], cv=5, scoring='f1_macro')\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"Gradient Boosting:\")\n",
    "print(f\"F1-macro scores por fold: {gb_scores}\")\n",
    "print(f\"F1-macro promedio: {gb_scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45ebc007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7389    0.9340    0.8251       500\n",
      "           1     0.5147    0.1750    0.2612       200\n",
      "\n",
      "    accuracy                         0.7171       700\n",
      "   macro avg     0.6268    0.5545    0.5431       700\n",
      "weighted avg     0.6749    0.7171    0.6640       700\n",
      "\n",
      "Matriz de confusión:\n",
      "[[467  33]\n",
      " [165  35]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Entrenar el modelo en todo el conjunto de entrenamiento\n",
    "gb_model.fit(X_train_reduced, train_df['Tag Value'])\n",
    "\n",
    "# Predecir sobre el conjunto de validación/desarrollo\n",
    "y_pred = gb_model.predict(X_dev_reduced)\n",
    "y_true = dev_df['Tag Value']\n",
    "\n",
    "# Imprimir el reporte de clasificación\n",
    "print(\"Reporte de clasificación:\")\n",
    "print(classification_report(y_true, y_pred, digits=4))\n",
    "\n",
    "# Imprimir la matriz de confusión\n",
    "print(\"Matriz de confusión:\")\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
